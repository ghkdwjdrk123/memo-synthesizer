# Step 3 (ZK - í˜ì–´ ì„ íƒ) êµ¬í˜„ ê³„íš - ì•Œê³ ë¦¬ì¦˜ ìˆ˜ì • ë²„ì „

## ëª©í‘œ
thought_units ê°„ **ë‚®ì€ ìœ ì‚¬ë„ (ì„œë¡œ ë‹¤ë¥¸ ì•„ì´ë””ì–´)**ë¥¼ ê³„ì‚°í•˜ì—¬ ZK "ì•½í•œ ì—°ê²°" í˜ì–´ë¥¼ ì°¾ê³ , Claudeë¡œ ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ì—¬ thought_pairs í…Œì´ë¸”ì— ì €ì¥

## âš ï¸ ì¤‘ìš”: ì•Œê³ ë¦¬ì¦˜ ë°©í–¥ ì „í™˜
- **ê¸°ì¡´ ë¬¸ì œ**: ìœ ì‚¬ë„ 0.3-0.7 = ë¹„ìŠ·í•œ ì•„ì´ë””ì–´ (ê°™ì€ ì£¼ì œì˜ ë‹¤ë¥¸ ê°ë„)
- **ìˆ˜ì • ë°©í–¥**: ìœ ì‚¬ë„ 0.05-0.35 = **ì„œë¡œ ë‹¤ë¥¸ ì•„ì´ë””ì–´** (ì˜ˆìƒ ë°–ì˜ ì—°ê²°)
- **ì¶”ê°€ ì œì•½**: ë™ì¼ ì¶œì²˜(raw_note) ìŒ ì œì™¸ â†’ ì„œë¡œ ë‹¤ë¥¸ ë©”ëª¨ì—ì„œë§Œ ì—°ê²°
- **Claude ì—­í• **: "ì–µì§€ ì—°ê²°" í•„í„°ë§ (threshold ê¸°ë°˜)

## í˜„ì¬ ìƒíƒœ

### âœ… ì™„ë£Œëœ ì‘ì—…
- **Step 1 (RAW)**: 5ê°œ Notion ë©”ëª¨ import ì™„ë£Œ
- **Step 2 (NORMALIZED)**: 11ê°œ ì‚¬ê³  ë‹¨ìœ„ ì¶”ì¶œ + ì„ë² ë”© ìƒì„± ì™„ë£Œ
- **ë°ì´í„°ë² ì´ìŠ¤**: thought_units í…Œì´ë¸”ì— 10ê°œ ë°ì´í„°, ëª¨ë‘ embedding ìˆìŒ
- **ì„ë² ë”© ëª¨ë¸**: text-embedding-3-small (1536 ì°¨ì›)

### ğŸ“Š ë°ì´í„° í˜„í™©
- **raw_notes**: 5ê°œ
- **thought_units**: 10ê°œ (ëª¨ë‘ embedding ìƒì„±ë¨)
- **ê°€ëŠ¥í•œ ìŒ**: C(10,2) = **45ê°œ ìŒ**
- **thought_pairs**: 0ê°œ (Step 3 êµ¬í˜„ ëŒ€ê¸°)

## Step 3 ì•Œê³ ë¦¬ì¦˜ (ìˆ˜ì •ëœ ë²„ì „)

### 1. ìœ ì‚¬ë„ ê³„ì‚° (pgvector) - ë‚®ì€ ìœ ì‚¬ë„ ì°¾ê¸°
```
similarity = 1 - (embedding_a <=> embedding_b)
```
- pgvectorì˜ `<=>` ì—°ì‚°ì: cosine distance (0=ë™ì¼, 2=ì •ë°˜ëŒ€)
- **ìˆ˜ì •ëœ íƒ€ê²Ÿ ë²”ìœ„**: **0.05 ~ 0.35** (ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ì˜ ì•„ì´ë””ì–´)
- **ì¶”ê°€ í•„í„°**: `a.raw_note_id != b.raw_note_id` (ë™ì¼ ì¶œì²˜ ì œì™¸)
- ì˜ˆìƒ: 45ê°œ ìŒ ì¤‘ 10-20ê°œê°€ ë²”ìœ„ ë‚´ ìœ„ì¹˜ (ì¶œì²˜ ì œì™¸ í›„ 5-15ê°œ)

**ìœ ì‚¬ë„ ì˜ë¯¸ í•´ì„:**
- 0.05-0.15: ê±°ì˜ ë¬´ê´€í•œ ì£¼ì œ (ì–µì§€ ì—°ê²° ê°€ëŠ¥ì„± ë†’ìŒ)
- 0.15-0.25: ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œ, ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥
- 0.25-0.35: ì•½ê°„ ê´€ë ¨, ì˜ˆìƒ ë°– ì—°ê²° ê°€ëŠ¥
- 0.35+: ì´ë¯¸ ìœ ì‚¬í•œ ì£¼ì œ (ZK "weak ties" ëª©í‘œì—ì„œ ë²—ì–´ë‚¨)

### 2. Claude í‰ê°€ - ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„±
- í›„ë³´ ìŒë“¤ì„ Claude Sonnet 4.5ì— ì „ë‹¬
- ê° ìŒì˜ **ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„±** ì ìˆ˜: 0-100
  - 0-40: ì–µì§€ ì—°ê²°, ë¬´ì˜ë¯¸í•œ ì¡°í•©
  - 41-64: ì—°ê²° ê°€ëŠ¥í•˜ë‚˜ í‰ë²”í•¨ (í•„í„°ë§ ê²½ê³„)
  - 65-85: ì‹ ì„ í•˜ê³  í¥ë¯¸ë¡œìš´ ì—°ê²° â† **threshold ê¸°ë³¸ê°’**
  - 86-100: ë§¤ìš° ì°½ì˜ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ì—°ê²°
- ì—°ê²° ì´ìœ (connection_reason) ìƒì„±
- **Threshold í•„í„°ë§**: `score >= min_score` (ê¸°ë³¸ 65)ë§Œ ì„ íƒ
- ìƒìœ„ Nê°œ ìŒ ì„ ì • (ê¸°ë³¸ 5ê°œ)

### 3. DB ì €ì¥
- thought_pairs í…Œì´ë¸”ì— ì €ì¥:
  - `thought_a_id`, `thought_b_id` (a < b ë³´ì¥, **ì„œë¡œ ë‹¤ë¥¸ raw_note**)
  - `similarity_score` (0.05-0.35, ë‚®ì„ìˆ˜ë¡ ì„œë¡œ ë‹¤ë¦„)
  - `connection_reason` (Claude ìƒì„±, ì°½ì˜ì  ì—°ê²° ì´ìœ )
  - `is_used_in_essay` (ê¸°ë³¸ê°’ FALSE)

## êµ¬í˜„ ê³„íš

### Phase 1: Pydantic ìŠ¤í‚¤ë§ˆ ìƒì„±

#### íŒŒì¼ 1: `backend/schemas/zk.py` (ì‹ ê·œ ìƒì„±)

**ëª¨ë¸ ì •ì˜:**
```python
class ThoughtPairCandidate(BaseModel):
    """ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼ (í›„ë³´ ìŒ)"""
    thought_a_id: int
    thought_b_id: int
    thought_a_claim: str
    thought_b_claim: str
    similarity_score: float = Field(..., ge=0, le=1)

class PairScoringRequest(BaseModel):
    """Claudeì—ê²Œ ë³´ë‚¼ í‰ê°€ ìš”ì²­"""
    pairs: list[ThoughtPairCandidate] = Field(..., min_length=1, max_length=20)

class PairScore(BaseModel):
    """Claudeê°€ ë°˜í™˜í•˜ëŠ” ë‹¨ì¼ ìŒ ì ìˆ˜"""
    thought_a_id: int
    thought_b_id: int
    logical_expansion_score: int = Field(..., ge=0, le=100)
    connection_reason: str = Field(..., min_length=10, max_length=300)

class PairScoringResult(BaseModel):
    """Claude í‰ê°€ ê²°ê³¼ (ì—¬ëŸ¬ ìŒ)"""
    pair_scores: list[PairScore] = Field(..., min_length=1)

class ThoughtPairCreate(BaseModel):
    """DB ì €ì¥ìš© ëª¨ë¸"""
    thought_a_id: int
    thought_b_id: int
    similarity_score: float = Field(..., ge=0, le=1)
    connection_reason: str = Field(..., max_length=500)

class ThoughtPairDB(ThoughtPairCreate):
    """DB ì¡°íšŒ ëª¨ë¸"""
    id: int
    selected_at: datetime
    is_used_in_essay: bool = False

    model_config = {"from_attributes": True}
```

**ë¼ì¸ ìˆ˜ ì˜ˆìƒ:** ~80 ë¼ì¸

#### íŒŒì¼ 2: `backend/schemas/essay.py` (ì‹ ê·œ ìƒì„±, Step 4 ëŒ€ë¹„)

**ëª¨ë¸ ì •ì˜:**
```python
class UsedThought(BaseModel):
    """ì—ì„¸ì´ì— ì‚¬ìš©ëœ ì‚¬ê³  ë‹¨ìœ„"""
    thought_id: int
    claim: str
    source_title: str
    source_url: str = Field(..., pattern=r'^https?://')

class EssayCreate(BaseModel):
    """ì—ì„¸ì´ ìƒì„± ìš”ì²­"""
    type: str = Field(default="essay")
    title: str = Field(..., min_length=5, max_length=100)
    outline: list[str] = Field(..., min_length=3, max_length=3)
    used_thoughts: list[UsedThought] = Field(..., min_length=1)
    reason: str = Field(..., max_length=300)
    pair_id: int

class EssayDB(EssayCreate):
    """DB ì¡°íšŒ ëª¨ë¸"""
    id: int
    generated_at: datetime

    model_config = {"from_attributes": True}
```

**ë¼ì¸ ìˆ˜ ì˜ˆìƒ:** ~50 ë¼ì¸

---

### Phase 2: Supabase Service í™•ì¥

**ì¤‘ìš”**: Stored Procedure ë¨¼ì € ìƒì„± í•„ìš”!

#### Step 2.1: Stored Procedure ìˆ˜ì • (SQL) - ë™ì¼ ì¶œì²˜ ì œì™¸

`docs/supabase_setup.sql` íŒŒì¼ì˜ ê¸°ì¡´ `find_similar_pairs()` í•¨ìˆ˜ë¥¼ ìˆ˜ì •:

```sql
-- Step 3: Stored Procedure for similarity search (ìˆ˜ì • ë²„ì „)
CREATE OR REPLACE FUNCTION find_similar_pairs(
    min_sim FLOAT DEFAULT 0.05,  -- ê¸°ë³¸ê°’ ë³€ê²½: 0.3 â†’ 0.05
    max_sim FLOAT DEFAULT 0.35,  -- ê¸°ë³¸ê°’ ë³€ê²½: 0.7 â†’ 0.35
    lim INT DEFAULT 20
)
RETURNS TABLE (
    thought_a_id INT,
    thought_b_id INT,
    thought_a_claim TEXT,
    thought_b_claim TEXT,
    similarity_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        a.id::INT as thought_a_id,
        b.id::INT as thought_b_id,
        a.claim as thought_a_claim,
        b.claim as thought_b_claim,
        (1 - (a.embedding <=> b.embedding))::FLOAT as similarity_score
    FROM thought_units a
    JOIN thought_units b ON a.id < b.id
    WHERE a.embedding IS NOT NULL
      AND b.embedding IS NOT NULL
      AND a.raw_note_id != b.raw_note_id  -- â­ ì¶”ê°€: ë™ì¼ ì¶œì²˜ ì œì™¸
      AND (1 - (a.embedding <=> b.embedding)) BETWEEN min_sim AND max_sim
    ORDER BY similarity_score DESC
    LIMIT lim;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION find_similar_pairs IS 'Step 3: Find thought unit pairs from DIFFERENT sources within low similarity range (weak ties)';
```

**ì‹¤í–‰ ë°©ë²•:**
1. Supabase Dashboard â†’ SQL Editor
2. ìœ„ SQL ì‹¤í–‰ (ê¸°ì¡´ í•¨ìˆ˜ë¥¼ ë®ì–´ì”€)
3. ì„±ê³µ í™•ì¸: `SELECT find_similar_pairs(0.05, 0.35, 5);`
4. **ë™ì¼ ì¶œì²˜ ì œì™¸ í™•ì¸**: ê²°ê³¼ì˜ ëª¨ë“  ìŒì´ ì„œë¡œ ë‹¤ë¥¸ raw_note_idë¥¼ ê°€ì ¸ì•¼ í•¨

#### Step 2.2: `backend/services/supabase_service.py` (í™•ì¥)

**ìƒˆ ë©”ì„œë“œ ì¶”ê°€:**

##### 1. `find_candidate_pairs()` - ë‚®ì€ ìœ ì‚¬ë„ í˜ì–´ ì¡°íšŒ (ìˆ˜ì •)
```python
async def find_candidate_pairs(
    self,
    min_similarity: float = 0.05,  # ê¸°ë³¸ê°’ ë³€ê²½: 0.3 â†’ 0.05
    max_similarity: float = 0.35,  # ê¸°ë³¸ê°’ ë³€ê²½: 0.7 â†’ 0.35
    limit: int = 20
) -> List[dict]:
    """
    pgvectorë¡œ ë‚®ì€ ìœ ì‚¬ë„ ë²”ìœ„ ë‚´ ìŒ ì°¾ê¸° (Stored Procedure í˜¸ì¶œ).
    ì„œë¡œ ë‹¤ë¥¸ raw_noteì—ì„œë§Œ í˜ì–´ ì„ íƒ (ë™ì¼ ì¶œì²˜ ì œì™¸).

    Args:
        min_similarity: ìµœì†Œ ìœ ì‚¬ë„ (ê¸°ë³¸ 0.05, ë‚®ì„ìˆ˜ë¡ ì„œë¡œ ë‹¤ë¥¸ ì•„ì´ë””ì–´)
        max_similarity: ìµœëŒ€ ìœ ì‚¬ë„ (ê¸°ë³¸ 0.35)
        limit: ìµœëŒ€ ë°˜í™˜ ê°œìˆ˜ (ê¸°ë³¸ 20)

    Returns:
        í›„ë³´ ìŒ ëª©ë¡ [
            {
                "thought_a_id": 1,
                "thought_b_id": 3,
                "thought_a_claim": "...",
                "thought_b_claim": "...",
                "similarity_score": 0.18  # ë‚®ì€ ê°’ = ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸
            }
        ]

    Raises:
        Exception: Stored Procedure í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
    """
    await self._ensure_initialized()

    try:
        response = await self.client.rpc(
            "find_similar_pairs",
            {
                "min_sim": min_similarity,
                "max_sim": max_similarity,
                "lim": limit
            }
        ).execute()

        candidates = response.data
        logger.info(f"Found {len(candidates)} candidate pairs from DIFFERENT sources (similarity {min_similarity}-{max_similarity})")
        return candidates

    except Exception as e:
        logger.error(f"Failed to find candidate pairs: {e}")
        # Stored Procedure ì—†ìœ¼ë©´ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€
        if "function find_similar_pairs" in str(e).lower():
            raise Exception(
                "Stored Procedure 'find_similar_pairs' not found. "
                "Please run docs/supabase_setup.sql first."
            )
        raise
```

##### 2. `insert_thought_pair()` - ë‹¨ì¼ í˜ì–´ ì €ì¥
```python
async def insert_thought_pair(self, pair: ThoughtPairCreate) -> dict:
    """thought_pairs í…Œì´ë¸”ì— ë‹¨ì¼ í˜ì–´ ì €ì¥"""
```

##### 3. `insert_thought_pairs_batch()` - ë°°ì¹˜ ì €ì¥
```python
async def insert_thought_pairs_batch(self, pairs: List[ThoughtPairCreate]) -> List[dict]:
    """ì—¬ëŸ¬ í˜ì–´ ë°°ì¹˜ ì €ì¥ (UPSERT)"""
```

##### 4. `get_unused_thought_pairs()` - ë¯¸ì‚¬ìš© í˜ì–´ ì¡°íšŒ
```python
async def get_unused_thought_pairs(self, limit: int = 10) -> List[dict]:
    """is_used_in_essay = FALSEì¸ í˜ì–´ ì¡°íšŒ (Step 4ìš©)"""
```

##### 5. `update_pair_used_status()` - ì‚¬ìš© ìƒíƒœ ì—…ë°ì´íŠ¸
```python
async def update_pair_used_status(self, pair_id: int, is_used: bool = True) -> dict:
    """ì—ì„¸ì´ ìƒì„± í›„ is_used_in_essay ì—…ë°ì´íŠ¸"""
```

##### 6. `get_pair_with_thoughts()` - í˜ì–´ + ì‚¬ê³  ë‹¨ìœ„ ì¡°íšŒ
```python
async def get_pair_with_thoughts(self, pair_id: int) -> dict:
    """
    í˜ì–´ ì •ë³´ì™€ ì–‘ìª½ ì‚¬ê³  ë‹¨ìœ„ë¥¼ JOINí•´ì„œ ì¡°íšŒ.
    Step 4ì—ì„œ ì—ì„¸ì´ ìƒì„± ì‹œ í•„ìš”.
    """
```

**ì¶”ê°€ ë¼ì¸ ìˆ˜ ì˜ˆìƒ:** ~150 ë¼ì¸

---

### Phase 3: AI Service í™•ì¥

#### íŒŒì¼: `backend/services/ai_service.py` (í™•ì¥)

**ìƒˆ ë©”ì„œë“œ ì¶”ê°€:**

##### `score_pairs()` - í˜ì–´ í‰ê°€ (í”„ë¡¬í”„íŠ¸ ì¬ì„¤ê³„)
```python
async def score_pairs(
    self,
    candidates: List[ThoughtPairCandidate],
    top_n: int = 5
) -> PairScoringResult:
    """
    ì—¬ëŸ¬ í›„ë³´ ìŒì˜ ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„± í‰ê°€.

    Args:
        candidates: ë‚®ì€ ìœ ì‚¬ë„ ë²”ìœ„ ë‚´ í›„ë³´ ìŒ ëª©ë¡ (ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸)
        top_n: ìƒìœ„ ëª‡ ê°œë¥¼ ì„ íƒí• ì§€ (ì‚¬ìš© ì•ˆ í•¨, threshold ê¸°ë°˜ í•„í„°ë§)

    Returns:
        PairScoringResult: ê° ìŒì˜ ì ìˆ˜ ë° ì—°ê²° ì´ìœ 
        ì£¼ì˜: ëª¨ë“  í›„ë³´ë¥¼ í‰ê°€, threshold í•„í„°ë§ì€ routerì—ì„œ ìˆ˜í–‰

    í”„ë¡¬í”„íŠ¸:
    - System: "ì„œë¡œ ë‹¤ë¥¸ ì•„ì´ë””ì–´ ê°„ ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€"
    - User: ê° ìŒì˜ claimì„ ì œê³µí•˜ê³  0-100 ì ìˆ˜ ìš”ì²­
    - ì–µì§€ ì—°ê²° ê°ì§€ ë° ë‚®ì€ ì ìˆ˜ ë¶€ì—¬
    - JSON ì‘ë‹µ ìš”êµ¬

    Model: claude-sonnet-4-5-20250929
    Max tokens: 2000
    """
```

**í”„ë¡¬í”„íŠ¸ ì„¤ê³„ (ì¬ì„¤ê³„):**
```python
system_message = """ë‹¹ì‹ ì€ ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ì˜ ì•„ì´ë””ì–´ ê°„ ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í‰ê°€ ëŒ€ìƒ ìŒë“¤ì€ ì˜ë„ì ìœ¼ë¡œ **ìœ ì‚¬ë„ê°€ ë‚®ì€** ì¡°í•©ì…ë‹ˆë‹¤ (ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œ).
ë‹¹ì‹ ì˜ ì—­í• ì€ ì–µì§€ìŠ¤ëŸ½ê±°ë‚˜ ë¬´ì˜ë¯¸í•œ ì—°ê²°ì„ ê±¸ëŸ¬ë‚´ê³ , ì§„ì •ìœ¼ë¡œ ì‹ ì„ í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ì—°ê²°ë§Œ ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.

ê° ìŒì— ëŒ€í•´:
1. ë‘ ì•„ì´ë””ì–´ê°€ ì–´ë–»ê²Œ ì°½ì˜ì ìœ¼ë¡œ ì—°ê²°ë  ìˆ˜ ìˆëŠ”ì§€ ë¶„ì„
2. ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„± ì ìˆ˜ (0-100) ë¶€ì—¬
   - 0-40: ì–µì§€ ì—°ê²°, ë¬´ì˜ë¯¸í•œ ì¡°í•© (ì˜ˆ: "ì»¤í”¼" + "ì–‘ìì—­í•™")
   - 41-64: ì—°ê²° ê°€ëŠ¥í•˜ë‚˜ í‰ë²”í•˜ê±°ë‚˜ í‘œë©´ì  (ì˜ˆ: "ìš´ë™" + "ê±´ê°•")
   - 65-85: ì‹ ì„ í•˜ê³  ì˜ˆìƒ ë°–ì˜ ì—°ê²° (ì˜ˆ: "ê²Œì„ ë‚œì´ë„" + "êµìœ¡ ìµœì  ë„ì „")
   - 86-100: ë§¤ìš° ì°½ì˜ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ì—°ê²° (ì˜ˆ: "ì •ì› ê°€ê¾¸ê¸°" + "ì†Œí”„íŠ¸ì›¨ì–´ ë¦¬íŒ©í† ë§")
3. ì—°ê²° ì´ìœ ë¥¼ ê°„ê²°í•˜ê²Œ (10-300ì) ì„¤ëª…

ì¤‘ìš” ì›ì¹™:
- ë‹¨ìˆœ ë‹¨ì–´ ìœ ì‚¬ì„±ì€ ë‚®ì€ ì ìˆ˜ (ì˜ˆ: "ì¼" + "ì§ì¥" = 40ì )
- ë¹„ìœ ë‚˜ ë©”íƒ€í¬ë¡œë§Œ ì—°ê²°ë˜ë©´ ì¤‘ê°„ ì ìˆ˜ (ì˜ˆ: "ì‚° ë“±ë°˜" + "ëª©í‘œ ë‹¬ì„±" = 55ì )
- ê·¼ë³¸ ì›ë¦¬ë‚˜ êµ¬ì¡°ì˜ ìœ ì‚¬ì„±ì€ ë†’ì€ ì ìˆ˜ (ì˜ˆ: "ìƒíƒœê³„ ê· í˜•" + "ê²½ì œ ìˆœí™˜" = 78ì )
- ì „í˜€ ë¬´ê´€í•œ ì¡°í•©ì€ ë§¤ìš° ë‚®ì€ ì ìˆ˜ (ì˜ˆ: "ì•„ì¹¨ì‹ì‚¬" + "ë¸”ë™í™€" = 15ì )"""

prompt = f"""ë‹¤ìŒ {len(candidates)}ê°œì˜ ì‚¬ê³  ë‹¨ìœ„ ìŒì„ í‰ê°€í•˜ì„¸ìš”.
ê° ìŒì€ ì„œë¡œ ë‹¤ë¥¸ ë©”ëª¨ ì¶œì²˜ì—ì„œ ê°€ì ¸ì˜¨ ê²ƒìœ¼ë¡œ, ìœ ì‚¬ë„ê°€ ë‚®ì€ ì¡°í•©ì…ë‹ˆë‹¤.

{pairs_text}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "pair_scores": [
    {{
      "thought_a_id": 1,
      "thought_b_id": 2,
      "logical_expansion_score": 72,
      "connection_reason": "Aì˜ í•µì‹¬ ì›ë¦¬ì™€ Bì˜ êµ¬ì¡°ëŠ” ..."
    }}
  ]
}}

ì¤‘ìš”: connection_reasonì€ í•œ ì¤„ë¡œ ì‘ì„± (ì¤„ë°”ê¿ˆ ê¸ˆì§€), 10-300ì.
JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."""
```

**ì¶”ê°€ ë¼ì¸ ìˆ˜ ì˜ˆìƒ:** ~100 ë¼ì¸

---

### Phase 4: Pipeline ë¼ìš°í„° í™•ì¥

#### íŒŒì¼: `backend/routers/pipeline.py` (í™•ì¥)

**ìƒˆ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€:**

##### 1. `POST /pipeline/select-pairs` - Step 3 ì‹¤í–‰ (ìˆ˜ì •)
```python
@router.post("/select-pairs")
async def select_pairs(
    min_similarity: float = Query(default=0.05, ge=0, le=1, description="ìµœì†Œ ìœ ì‚¬ë„"),  # ë³€ê²½: 0.3 â†’ 0.05
    max_similarity: float = Query(default=0.35, ge=0, le=1, description="ìµœëŒ€ ìœ ì‚¬ë„"),  # ë³€ê²½: 0.7 â†’ 0.35
    min_score: int = Query(default=65, ge=0, le=100, description="ìµœì†Œ ì°½ì˜ì  ì—°ê²° ì ìˆ˜ (threshold)"),  # â­ ì¶”ê°€
    top_n: int = Query(default=5, ge=1, le=20, description="ì„ íƒí•  í˜ì–´ ê°œìˆ˜"),
    supabase_service: SupabaseService = Depends(get_supabase_service),
    ai_service: AIService = Depends(get_ai_service),
):
    """
    Step 3: ZK í˜ì–´ ì„ íƒ (ë‚®ì€ ìœ ì‚¬ë„ + Claude í•„í„°ë§)

    í”„ë¡œì„¸ìŠ¤:
    1. find_candidate_pairs()ë¡œ ë‚®ì€ ìœ ì‚¬ë„ ë²”ìœ„ ë‚´ ìŒ ì¡°íšŒ (ì„œë¡œ ë‹¤ë¥¸ ì¶œì²˜)
    2. í›„ë³´ê°€ ì—†ìœ¼ë©´ Fallback ì „ëµ (ë²”ìœ„ í™•ëŒ€)
    3. ai_service.score_pairs()ë¡œ Claude í‰ê°€
    4. min_score ì´ìƒì¸ ìŒë§Œ í•„í„°ë§ (threshold)
    5. ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ top_nê°œ ì„ íƒ
    6. insert_thought_pairs_batch()ë¡œ DB ì €ì¥
    7. ì €ì¥ëœ í˜ì–´ ê°œìˆ˜ ë° ìƒ˜í”Œ ë°˜í™˜

    Args:
        min_similarity: ìµœì†Œ ìœ ì‚¬ë„ (ê¸°ë³¸ 0.05, ë‚®ì„ìˆ˜ë¡ ë‹¤ë¥¸ ì•„ì´ë””ì–´)
        max_similarity: ìµœëŒ€ ìœ ì‚¬ë„ (ê¸°ë³¸ 0.35)
        min_score: ìµœì†Œ ì°½ì˜ì  ì—°ê²° ì ìˆ˜ (ê¸°ë³¸ 65, ì‚¬ìš©ì ì¡°ì • ê°€ëŠ¥)
        top_n: ì„ íƒí•  í˜ì–´ ê°œìˆ˜ (ê¸°ë³¸ 5)

    Returns:
        {
            "success": true,
            "candidates_found": 12,
            "candidates_after_threshold": 7,  # min_score í•„í„° í›„
            "pairs_selected": 5,
            "pairs": [
                {
                    "thought_a_id": 1,
                    "thought_b_id": 3,
                    "similarity": 0.18,  # ë‚®ì€ ê°’ = ì„œë¡œ ë‹¤ë¦„
                    "score": 78,
                    "reason": "..."
                }
            ]
        }
    """
```

**ì²˜ë¦¬ íë¦„ (ìˆ˜ì •):**
1. ìœ ì‚¬ë„ ë²”ìœ„ ê²€ì¦ (min < max)
2. Supabaseì—ì„œ ë‚®ì€ ìœ ì‚¬ë„ í›„ë³´ ìŒ ì¡°íšŒ (ì„œë¡œ ë‹¤ë¥¸ raw_note)
3. í›„ë³´ê°€ ì—†ìœ¼ë©´ **Fallback ì „ëµ**:
   - 1ì°¨: ë²”ìœ„ 0.05-0.35 (ê¸°ë³¸)
   - 2ì°¨: ë²”ìœ„ 0.1-0.4 (í™•ëŒ€)
   - 3ì°¨: ë²”ìœ„ 0.15-0.45 (ë” í™•ëŒ€)
   - ëª¨ë‘ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜
4. Claudeë¡œ í‰ê°€ (ë°°ì¹˜ ì²˜ë¦¬)
5. **min_score ì´ìƒì¸ ìŒë§Œ í•„í„°ë§** (ì˜ˆ: 65ì  ì´ìƒ)
6. ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ top_nê°œ ì„ íƒ
7. DB ì €ì¥ (UPSERT)
8. ê²°ê³¼ ë°˜í™˜

##### 2. `GET /pipeline/pairs` - ì €ì¥ëœ í˜ì–´ ì¡°íšŒ
```python
@router.get("/pairs")
async def get_pairs(
    only_unused: bool = Query(False),
    limit: int = Query(10, ge=1, le=100),
    supabase_service: SupabaseService = Depends(get_supabase_service),
):
    """ì €ì¥ëœ thought_pairs ì¡°íšŒ (ë¯¸ì‚¬ìš©/ì „ì²´)"""
```

##### 3. `POST /pipeline/run-all` - ì „ì²´ íŒŒì´í”„ë¼ì¸ (Step 1-3, ìˆ˜ì •)
```python
@router.post("/run-all")
async def run_all_pipeline(
    page_size: int = Query(default=100, ge=1, le=100),
    min_similarity: float = Query(default=0.05, ge=0, le=1),  # ë³€ê²½: 0.3 â†’ 0.05
    max_similarity: float = Query(default=0.35, ge=0, le=1),  # ë³€ê²½: 0.7 â†’ 0.35
    min_score: int = Query(default=65, ge=0, le=100),  # â­ ì¶”ê°€
    top_n: int = Query(default=5, ge=1, le=20),
    ...
):
    """
    Step 1 â†’ Step 2 â†’ Step 3 ìˆœì°¨ ì‹¤í–‰
    ê° ë‹¨ê³„ë³„ ê²°ê³¼ ë°˜í™˜

    ì£¼ì˜: Step 3 íŒŒë¼ë¯¸í„°ê°€ ìˆ˜ì •ë¨ (ë‚®ì€ ìœ ì‚¬ë„ + threshold)
    """
```

**ì¶”ê°€ ë¼ì¸ ìˆ˜ ì˜ˆìƒ:** ~200 ë¼ì¸

---

## êµ¬í˜„ íŒŒì¼ ìš”ì•½

| íŒŒì¼ | ì‘ì—… | ì˜ˆìƒ ë¼ì¸ ìˆ˜ |
|------|------|-------------|
| `backend/schemas/zk.py` | ì‹ ê·œ ìƒì„± | ~80 ë¼ì¸ |
| `backend/schemas/essay.py` | ì‹ ê·œ ìƒì„± (Step 4 ëŒ€ë¹„) | ~50 ë¼ì¸ |
| `backend/services/supabase_service.py` | 6ê°œ ë©”ì„œë“œ ì¶”ê°€ | +150 ë¼ì¸ |
| `backend/services/ai_service.py` | 1ê°œ ë©”ì„œë“œ ì¶”ê°€ | +100 ë¼ì¸ |
| `backend/routers/pipeline.py` | 3ê°œ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ | +200 ë¼ì¸ |
| **í•©ê³„** | | **~580 ë¼ì¸** |

---

## í…ŒìŠ¤íŠ¸ ê³„íš

### 1. ìœ ì‚¬ë„ ë¶„í¬ í™•ì¸ (ì‹¤í–‰ ì „)
```sql
-- 45ê°œ ìŒì˜ ìœ ì‚¬ë„ ë¶„í¬ í™•ì¸
SELECT
    COUNT(*) as total_pairs,
    COUNT(CASE WHEN sim >= 0.3 AND sim <= 0.7 THEN 1 END) as weak_connections,
    MIN(sim) as min_similarity,
    MAX(sim) as max_similarity,
    AVG(sim) as avg_similarity
FROM (
    SELECT 1 - (a.embedding <=> b.embedding) as sim
    FROM thought_units a, thought_units b
    WHERE a.id < b.id
) subquery;
```

### 2. Step 3 ì‹¤í–‰ (ìˆ˜ì •ëœ íŒŒë¼ë¯¸í„°)
```bash
# ê¸°ë³¸ê°’ ì‚¬ìš© (ë‚®ì€ ìœ ì‚¬ë„ 0.05-0.35, threshold=65)
curl -X POST "http://localhost:8000/pipeline/select-pairs"

# íŒŒë¼ë¯¸í„° ì¡°ì • ì˜ˆì‹œ
curl -X POST "http://localhost:8000/pipeline/select-pairs?min_similarity=0.05&max_similarity=0.35&min_score=70&top_n=5"

# Threshold ë‚®ì¶”ê¸° (ë” ë§ì€ í›„ë³´ í—ˆìš©)
curl -X POST "http://localhost:8000/pipeline/select-pairs?min_score=60"
```

### 3. ê²°ê³¼ ê²€ì¦
```sql
-- ì €ì¥ëœ í˜ì–´ í™•ì¸
SELECT
    tp.id,
    tp.thought_a_id,
    tp.thought_b_id,
    tp.similarity_score,
    tp.connection_reason,
    ta.claim as thought_a,
    tb.claim as thought_b
FROM thought_pairs tp
JOIN thought_units ta ON tp.thought_a_id = ta.id
JOIN thought_units tb ON tp.thought_b_id = tb.id
ORDER BY tp.similarity_score DESC;
```

---

## ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

### pgvector ì¸ë±ìŠ¤
- í˜„ì¬ 10ê°œ thought_units â†’ ì¸ë±ìŠ¤ ë¶ˆí•„ìš”
- 1000+ ë ˆì½”ë“œ ì‹œ ivfflat ì¸ë±ìŠ¤ ìƒì„± ê¶Œì¥:
```sql
CREATE INDEX idx_thought_units_embedding
ON thought_units
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

### Claude API í˜¸ì¶œ ìµœì í™”
- í›„ë³´ ìŒì„ í•œ ë²ˆì— ë°°ì¹˜ ì²˜ë¦¬ (ìµœëŒ€ 20ê°œ)
- Rate limiting ì ìš© (5 req/sec)
- í† í° ì‚¬ìš©ëŸ‰: ~500-1000 tokens per request

---

## ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (ì„ì‹œ íŒŒì¼)

ì‹¤í–‰ í›„ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ `temp/verification/`ì— ìƒì„±:

### `temp/verification/verify_step3.py`
- thought_pairs í…Œì´ë¸” ë°ì´í„° í™•ì¸
- ìœ ì‚¬ë„ ë²”ìœ„ ê²€ì¦
- connection_reason í’ˆì§ˆ í™•ì¸
- ìƒìœ„ 5ê°œ í˜ì–´ ì¶œë ¥

### `temp/verification/analyze_similarity.py`
- 45ê°œ ìŒì˜ ìœ ì‚¬ë„ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
- 0.3-0.7 ë²”ìœ„ ë¹„ìœ¨ ë¶„ì„
- ê°€ì¥ ìœ ì‚¬í•œ/ë¨¼ ìŒ ì¶œë ¥

---

## ì˜ˆìƒ ê²°ê³¼

### Step 3 ì‹¤í–‰ ì„±ê³µ ì‹œ:
```json
{
  "success": true,
  "candidates_found": 12,
  "pairs_selected": 5,
  "pairs": [
    {
      "id": 1,
      "thought_a_id": 2,
      "thought_b_id": 5,
      "similarity_score": 0.52,
      "logical_expansion_score": 82,
      "connection_reason": "ê²Œì„ì„ ì‰¬ë©´ì„œ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ëŠ” ìƒê°ê³¼ ì¼ë¡œ ì •ì˜ë˜ëŠ” ì •ì²´ì„±ì€, ë…¸ë ¥ì˜ ë³¸ì§ˆê³¼ ìì•„ì‹¤í˜„ì˜ ì—°ê²°ê³ ë¦¬ë¥¼ ì œì‹œí•  ìˆ˜ ìˆë‹¤."
    },
    ...
  ]
}
```

### thought_pairs í…Œì´ë¸”:
- 5ê°œ í–‰ ìƒì„±
- similarity_score: 0.3-0.7 ë²”ìœ„
- connection_reason: Claude ìƒì„± í…ìŠ¤íŠ¸ (10-300ì)
- is_used_in_essay: FALSE (Step 4 ëŒ€ê¸°)

---

## ë‹¤ìŒ ë‹¨ê³„: Step 4

Step 3 ì™„ë£Œ í›„:
1. thought_pairsì—ì„œ ë¯¸ì‚¬ìš© í˜ì–´ ì¡°íšŒ
2. Claudeë¡œ ì—ì„¸ì´ ìƒì„± (title, 3ë‹¨ outline, reason)
3. essays í…Œì´ë¸” ì €ì¥
4. thought_pairs.is_used_in_essay = TRUE ì—…ë°ì´íŠ¸

---

## íŒŒì¼ ì •ë¦¬ ê·œì¹™ (ì‚¬ìš©ì ìš”ì²­)

**ì•ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ì„ì‹œ íŒŒì¼ ê´€ë¦¬:**
- ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (.py) â†’ `temp/verification/`
- ì‹¤í—˜ ê²°ê³¼ (.md) â†’ `temp/experiments/`
- ë°±ì—… íŒŒì¼ (.sql) â†’ `temp/experiments/`
- ì‚¬ìš© ì™„ë£Œ í›„ ì •ë¦¬

**í•µì‹¬ ë¬¸ì„œ:**
- DB ìŠ¤í‚¤ë§ˆ â†’ `docs/`
- ê²€ì¦ ìš”ì•½ â†’ `docs/`
- README â†’ `docs/`

---

## ì‹¤í–‰ ìˆœì„œ

1. **Phase 1**: schemas/zk.py, schemas/essay.py ìƒì„±
2. **Phase 2**: supabase_service.py ë©”ì„œë“œ 6ê°œ ì¶”ê°€
3. **Phase 3**: ai_service.py score_pairs() ë©”ì„œë“œ ì¶”ê°€
4. **Phase 4**: pipeline.py ì—”ë“œí¬ì¸íŠ¸ 3ê°œ ì¶”ê°€
5. **í…ŒìŠ¤íŠ¸**: ìœ ì‚¬ë„ ë¶„í¬ í™•ì¸ â†’ Step 3 ì‹¤í–‰ â†’ ê²°ê³¼ ê²€ì¦
6. **ë¬¸ì„œí™”**: ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ temp/verification/ì— ìƒì„±

---

## ì£¼ì˜ì‚¬í•­ ë° íŠ¹ì´ ì¼€ì´ìŠ¤

### 1. pgvector ê´€ë ¨
- **ë¬¸ë²•**: `<=>` ëŠ” cosine distance (0=ë™ì¼, 2=ì •ë°˜ëŒ€)
- **NULL embedding**: thought_unitsì— embeddingì´ NULLì¸ ë ˆì½”ë“œê°€ ìˆìœ¼ë©´ ì—ëŸ¬ ë°œìƒ
  - **ëŒ€ì‘**: `find_candidate_pairs()` ì—ì„œ `WHERE a.embedding IS NOT NULL AND b.embedding IS NOT NULL` ì¡°ê±´ ì¶”ê°€
- **pgvector extension ë¯¸ì„¤ì¹˜**: Supabaseì—ì„œ extension í™œì„±í™” ì—¬ë¶€ í™•ì¸ í•„ìš”
  - **ëŒ€ì‘**: ì—ëŸ¬ ë°œìƒ ì‹œ ëª…í™•í•œ ë©”ì‹œì§€ë¡œ ì•ˆë‚´

### 2. ë°ì´í„° ì œì•½ ì¡°ê±´
- **ordered_pair ì œì•½**: `thought_a_id < thought_b_id` ë³´ì¥ í•„ìš”
  - **ëŒ€ì‘**: SQL ì¿¼ë¦¬ì—ì„œ `a.id < b.id` ì¡°ê±´ìœ¼ë¡œ ìë™ ë³´ì¥
  - **ì¶”ê°€ ì•ˆì „ì¥ì¹˜**: Pythonì—ì„œë„ `min(id1, id2), max(id1, id2)` ë¡œ ì •ë ¬
- **UNIQUE ì œì•½**: `(thought_a_id, thought_b_id)` ì¤‘ë³µ ì €ì¥ ë°©ì§€
  - **ëŒ€ì‘**: UPSERT ì‚¬ìš©, ì¶©ëŒ ì‹œ ì—…ë°ì´íŠ¸
- **ë™ì¼ thought ìŒ**: `thought_a_id = thought_b_id` ë°©ì§€
  - **ëŒ€ì‘**: SQLì—ì„œ `a.id < b.id` ë¡œ ìë™ ë°©ì§€ (ë“±í˜¸ ì œì™¸)

### 3. ìœ ì‚¬ë„ ê³„ì‚° íŠ¹ì´ ì¼€ì´ìŠ¤ (ìˆ˜ì •)
- **í›„ë³´ ìŒ 0ê°œ**: 0.05-0.35 ë²”ìœ„ì— ìŒì´ ì—†ëŠ” ê²½ìš°
  - **ëŒ€ì‘ 1ì°¨**: Fallback ì „ëµ (0.1-0.4 â†’ 0.15-0.45 ìˆœì°¨ í™•ëŒ€)
  - **ëŒ€ì‘ 2ì°¨**: ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ + ì „ì²´ ìœ ì‚¬ë„ ë¶„í¬ í†µê³„ ì œê³µ
  - **ì œì•ˆ**: "ë©”ëª¨ë¥¼ ë” ì¶”ê°€í•˜ê±°ë‚˜ ë²”ìœ„ë¥¼ ì¡°ì •í•˜ì„¸ìš”"
- **í›„ë³´ ìŒì´ ë„ˆë¬´ ë§ìŒ**: 45ê°œ ëª¨ë‘ê°€ 0.05-0.35 ë²”ìœ„ì¸ ê²½ìš° (ê±°ì˜ ì—†ìŒ)
  - **ëŒ€ì‘**: LIMIT íŒŒë¼ë¯¸í„°ë¡œ ìƒìœ„ Nê°œë§Œ ì¡°íšŒ (ê¸°ë³¸ 20ê°œ)
- **ìœ ì‚¬ë„ 1.0 (ë™ì¼ ì„ë² ë”©)**: ë™ì¼í•œ claimìœ¼ë¡œ ì¤‘ë³µ ìƒì„±ëœ ê²½ìš°
  - **ëŒ€ì‘**: 0.05-0.35 ë²”ìœ„ í•„í„°ë¡œ ìë™ ì œì™¸ë¨
- **ë™ì¼ ì¶œì²˜ ìŒ**: ê°™ì€ raw_note_idì—ì„œ ë‚˜ì˜¨ ìŒ
  - **ëŒ€ì‘**: Stored Procedureì—ì„œ `a.raw_note_id != b.raw_note_id` ì¡°ê±´ìœ¼ë¡œ ìë™ ì œì™¸
- **Threshold í•„í„° í›„ 0ê°œ**: Claude í‰ê°€ì—ì„œ ëª¨ë‘ 65ì  ë¯¸ë§Œì¸ ê²½ìš°
  - **ëŒ€ì‘**: ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ + min_score ë‚®ì¶”ê¸° ì œì•ˆ (ì˜ˆ: 60ì )
  - **ë¡œê¹…**: í•„í„°ë§ ì „í›„ ê°œìˆ˜ ê¸°ë¡ (candidates_found vs candidates_after_threshold)

### 4. Claude API í˜¸ì¶œ ê´€ë ¨
- **JSON íŒŒì‹± ì‹¤íŒ¨**: Claudeê°€ ```json ë§ˆí¬ë‹¤ìš´ í¬í•¨í•˜ëŠ” ê²½ìš°
  - **ëŒ€ì‘**: Step 2ì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ ë¡œì§ ì ìš©
  - ì½”ë“œ: `content.strip().removeprefix("```json").removeprefix("```").removesuffix("```")`
- **Claudeê°€ ì ìˆ˜ ë²”ìœ„ ìœ„ë°˜**: logical_expansion_scoreê°€ 0-100 ë°–ì¸ ê²½ìš°
  - **ëŒ€ì‘**: Pydantic Field(..., ge=0, le=100) ê²€ì¦ìœ¼ë¡œ ìë™ ì—ëŸ¬
- **Claudeê°€ ì¼ë¶€ ìŒë§Œ ë°˜í™˜**: 10ê°œ ìš”ì²­í–ˆëŠ”ë° 8ê°œë§Œ ë°˜í™˜
  - **ëŒ€ì‘**: ì •ìƒ ì²˜ë¦¬, ë°˜í™˜ëœ ê²ƒë§Œ ì €ì¥ (ì—ëŸ¬ ì•„ë‹˜)
- **connection_reasonì´ ë„ˆë¬´ ê¹€**: 300ì ì´ˆê³¼
  - **ëŒ€ì‘**: Pydantic Field(..., max_length=300) ê²€ì¦
  - **ì¶”ê°€ ëŒ€ì‘**: í”„ë¡¬í”„íŠ¸ì— "10-300ì" ëª…ì‹œ
- **Claude API ì‹¤íŒ¨**: Rate limit, í¬ë ˆë”§ ë¶€ì¡±, ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬
  - **ëŒ€ì‘**: try-exceptë¡œ ì¡ê³  ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
  - **ì¬ì‹œë„ ë¡œì§**: ì„ íƒì ìœ¼ë¡œ ì¶”ê°€ (ì¼ë‹¨ 1íšŒ ì‹œë„ë§Œ)

### 5. ë°°ì¹˜ ì²˜ë¦¬ íŠ¹ì´ ì¼€ì´ìŠ¤
- **í›„ë³´ ìŒ 20ê°œ ì´ˆê³¼**: Claudeì— í•œ ë²ˆì— ë„ˆë¬´ ë§ì´ ë³´ë‚´ë©´ ì‘ë‹µ í’ˆì§ˆ ì €í•˜
  - **ëŒ€ì‘**: ìµœëŒ€ 20ê°œë¡œ ì œí•œ (limit íŒŒë¼ë¯¸í„°)
  - **í–¥í›„ ê°œì„ **: í•„ìš” ì‹œ 10ê°œì”© ë°°ì¹˜ ë¶„í•  ì²˜ë¦¬
- **top_n > í›„ë³´ ê°œìˆ˜**: 5ê°œ ìš”ì²­í–ˆëŠ”ë° í›„ë³´ê°€ 3ê°œë§Œ ìˆëŠ” ê²½ìš°
  - **ëŒ€ì‘**: min(top_n, len(candidates)) ë¡œ ì¡°ì •

### 6. DB ì €ì¥ íŠ¹ì´ ì¼€ì´ìŠ¤
- **ê°™ì€ ìŒì„ ë‹¤ì‹œ ì €ì¥**: ì¤‘ë³µ ì‹¤í–‰ ì‹œ UNIQUE ì œì•½ ìœ„ë°˜
  - **ëŒ€ì‘**: UPSERT (ON CONFLICT UPDATE) ì‚¬ìš©
  - **ê²°ì •**: ìƒˆë¡œìš´ ì ìˆ˜/ì´ìœ ë¡œ ì—…ë°ì´íŠ¸ vs ê¸°ì¡´ ìœ ì§€?
  - **ê¶Œì¥**: ì—…ë°ì´íŠ¸ (ìµœì‹  Claude í‰ê°€ ë°˜ì˜)
- **thought_units ì‚­ì œ í›„ ì¬ìƒì„±**: IDê°€ ë°”ë€Œë©´ ê¸°ì¡´ pairsê°€ dangling reference
  - **ëŒ€ì‘**: DB ìŠ¤í‚¤ë§ˆì— ON DELETE CASCADE ì„¤ì •ë˜ì–´ ìˆìŒ
- **is_used_in_essayê°€ ì´ë¯¸ TRUE**: ì¬ì‹¤í–‰ ì‹œ ê¸°ì‚¬ìš© í˜ì–´ ë®ì–´ì“°ê¸° ë°©ì§€?
  - **ëŒ€ì‘**: UPSERT ì‹œ is_used_in_essayëŠ” ì—…ë°ì´íŠ¸í•˜ì§€ ì•Šë„ë¡ ì„¤ì •
  - **SQL**: `ON CONFLICT ... DO UPDATE SET ... (is_used_in_essay ì œì™¸)`

### 7. Step 1/2ì™€ì˜ ì¼ê´€ì„±
- **ë¹„ë™ê¸° íŒ¨í„´**: Step 1/2ì™€ ë™ì¼í•œ async/await íŒ¨í„´ ì‚¬ìš©
- **ì—ëŸ¬ ì²˜ë¦¬**: ë™ì¼í•œ try-except + HTTPException êµ¬ì¡°
- **ë¡œê¹…**: logger.info/warning/error ì¼ê´€ì„± ìœ ì§€
- **ì‘ë‹µ í¬ë§·**: Step 1/2ì™€ ìœ ì‚¬í•œ JSON êµ¬ì¡° (success, errors ë“±)

### 8. Supabase RPC ëŒ€ì‹  SQL ì‹¤í–‰
- **ë¬¸ì œ**: Supabase Python í´ë¼ì´ì–¸íŠ¸ëŠ” ì§ì ‘ SQL ì‹¤í–‰ ë¶ˆê°€
- **í•´ê²°**: PostgRESTì˜ `.rpc()` ì‚¬ìš©í•˜ê±°ë‚˜, SQLì„ í…Œì´ë¸” ì—°ì‚°ìœ¼ë¡œ ë³€í™˜
- **ëŒ€ì•ˆ 1**: Stored Procedure ìƒì„± (supabase_setup.sqlì— ì¶”ê°€)
  ```sql
  CREATE OR REPLACE FUNCTION find_similar_pairs(
      min_sim FLOAT, max_sim FLOAT, lim INT
  ) RETURNS TABLE (...) AS $$
  BEGIN
      RETURN QUERY
      SELECT ... FROM thought_units a, thought_units b
      WHERE a.id < b.id AND ...;
  END;
  $$ LANGUAGE plpgsql;
  ```
- **ëŒ€ì•ˆ 2**: Pythonì—ì„œ ëª¨ë“  thought_units ê°€ì ¸ì™€ ê³„ì‚° (ë¹„íš¨ìœ¨)
- **ê¶Œì¥**: **ëŒ€ì•ˆ 1** (Stored Procedure ì‚¬ìš©)

### 9. íƒ€ì… ì•ˆì „ì„±
- **UUID vs str**: raw_note_idëŠ” UUID íƒ€ì…
  - **ëŒ€ì‘**: Pydantic ëª¨ë¸ì—ì„œ UUID íƒ€ì… ì‚¬ìš©
- **float vs Decimal**: similarity_scoreëŠ” Python float
  - **ëŒ€ì‘**: PostgreSQL FLOATì™€ í˜¸í™˜ë¨, ë¬¸ì œ ì—†ìŒ
- **datetime ì§ë ¬í™”**: selected_atì€ datetime
  - **ëŒ€ì‘**: model_dump(mode='json') ì‚¬ìš© (Step 2 íŒ¨í„´)

### 10. í”„ë¡ íŠ¸ì—”ë“œ í†µí•© ëŒ€ë¹„
- **CORS ì„¤ì •**: ì´ë¯¸ main.pyì— ì„¤ì •ë˜ì–´ ìˆìŒ (í™•ì¸ ì™„ë£Œ)
- **ì‘ë‹µ ì†ë„**: Claude í˜¸ì¶œ + DB ì¿¼ë¦¬ = 3-10ì´ˆ ì˜ˆìƒ
  - **ëŒ€ì‘**: í”„ë¡ íŠ¸ì—”ë“œì— ë¡œë”© í‘œì‹œ í•„ìš” (êµ¬í˜„ ì‹œ ì•ˆë‚´)
- **ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸**: WebSocket ë˜ëŠ” SSEë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸?
  - **ì¼ë‹¨ ì œì™¸**: Step 3ì€ í•œ ë²ˆì— ì™„ë£Œ (ë°°ì¹˜ ì‘ìŒ)

---

## ğŸ”§ êµ¬í˜„ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1 ì™„ë£Œ ì¡°ê±´
- [ ] schemas/zk.pyì— ëª¨ë“  ëª¨ë¸ ì •ì˜ (6ê°œ í´ë˜ìŠ¤)
- [ ] schemas/essay.pyì— ëª¨ë“  ëª¨ë¸ ì •ì˜ (3ê°œ í´ë˜ìŠ¤)
- [ ] datetime, UUID import í™•ì¸

### Phase 2 ì™„ë£Œ ì¡°ê±´
- [ ] Stored Procedure `find_similar_pairs()` ì‘ì„± (SQL)
- [ ] supabase_service.pyì— 6ê°œ ë©”ì„œë“œ ì¶”ê°€
- [ ] NULL embedding í•„í„°ë§ ì¡°ê±´ í¬í•¨
- [ ] UPSERT ON CONFLICT ì²˜ë¦¬ (is_used_in_essay ì œì™¸)

### Phase 3 ì™„ë£Œ ì¡°ê±´
- [ ] ai_service.pyì˜ score_pairs() ë©”ì„œë“œ
- [ ] JSON íŒŒì‹± ì „ì²˜ë¦¬ (```json ì œê±°)
- [ ] Pydantic ê²€ì¦ ì—ëŸ¬ ì²˜ë¦¬
- [ ] í”„ë¡¬í”„íŠ¸ ëª…í™•ì„± (ì ìˆ˜ ê¸°ì¤€, ê¸¸ì´ ì œí•œ)

### Phase 4 ì™„ë£Œ ì¡°ê±´
- [ ] /pipeline/select-pairs ì—”ë“œí¬ì¸íŠ¸
- [ ] min < max ê²€ì¦
- [ ] í›„ë³´ 0ê°œ ì—ëŸ¬ ì²˜ë¦¬ + íŒíŠ¸ ì œê³µ
- [ ] top_n vs í›„ë³´ ê°œìˆ˜ ì¡°ì •
- [ ] /pipeline/pairs GET ì—”ë“œí¬ì¸íŠ¸
- [ ] /pipeline/run-all ì—”ë“œí¬ì¸íŠ¸ (ì„ íƒ)

### í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì¡°ê±´
- [ ] ìœ ì‚¬ë„ ë¶„í¬ í™•ì¸ ì¿¼ë¦¬ ì‹¤í–‰
- [ ] Step 3 ì‹¤í–‰ (curl ë˜ëŠ” Swagger UI)
- [ ] thought_pairs í…Œì´ë¸” ë°ì´í„° ê²€ì¦
- [ ] ì¬ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (UPSERT ë™ì‘ í™•ì¸)
- [ ] ì—ëŸ¬ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ (í›„ë³´ 0ê°œ, Claude ì‹¤íŒ¨ ë“±)

### ë¬¸ì„œí™” ì™„ë£Œ ì¡°ê±´
- [ ] temp/verification/verify_step3.py ìƒì„±
- [ ] temp/verification/analyze_similarity.py ìƒì„±
- [ ] docs/VERIFICATION_SUMMARY.md ì—…ë°ì´íŠ¸ (Step 3 ì„¹ì…˜ ì¶”ê°€)

---

## âš ï¸ ì¹˜ëª…ì  ì—ëŸ¬ ë°©ì§€ ê·œì¹™

1. **pgvector extension í™•ì¸**: ì²« ì‹¤í–‰ ì „ Supabaseì—ì„œ `CREATE EXTENSION vector` ì‹¤í–‰ í™•ì¸
2. **Stored Procedure ë¨¼ì € ìƒì„±**: find_similar_pairs() ì—†ìœ¼ë©´ Step 3 ì‹¤í–‰ ë¶ˆê°€
3. **embedding NULL ì²´í¬**: í•„ìˆ˜! ì—†ìœ¼ë©´ pgvector ì—°ì‚° ì—ëŸ¬
4. **ordered_pair ë³´ì¥**: a.id < b.id ì¡°ê±´ ëˆ„ë½ ì‹œ ì¤‘ë³µ ìŒ ìƒì„±
5. **UPSERT ì„¤ì •**: ON CONFLICT ì—†ìœ¼ë©´ UNIQUE ì œì•½ ìœ„ë°˜ ì—ëŸ¬

---

## ğŸ”„ ì•Œê³ ë¦¬ì¦˜ ë³€ê²½ ìš”ì•½

### ë³€ê²½ ì „ (ë¬¸ì œ ìˆë˜ ë°©ì‹)
| ìš”ì†Œ | ê¸°ì¡´ ê°’ | ë¬¸ì œì  |
|------|---------|--------|
| ìœ ì‚¬ë„ ë²”ìœ„ | 0.3 - 0.7 | ë¹„ìŠ·í•œ ì£¼ì œ ì„ íƒ (ê°™ì€ ì£¼ì œì˜ ë‹¤ë¥¸ ê°ë„) |
| ì¶œì²˜ ì œì•½ | ì—†ìŒ | ê°™ì€ ë©”ëª¨ ë‚´ ìŒ ì—°ê²° ê°€ëŠ¥ |
| Claude ì—­í•  | ë…¼ë¦¬ì  í™•ì¥ | ì´ë¯¸ ìœ ì‚¬í•œ ì•„ì´ë””ì–´ ì—°ê²° |
| í•„í„°ë§ | ì ìˆ˜ ì •ë ¬ë§Œ | ì–µì§€ ì—°ê²° ê±¸ëŸ¬ë‚´ê¸° ì–´ë ¤ì›€ |

### ë³€ê²½ í›„ (ìˆ˜ì •ëœ ë°©ì‹)
| ìš”ì†Œ | ìˆ˜ì • ê°’ | í•´ê²° ë°©ë²• |
|------|---------|----------|
| ìœ ì‚¬ë„ ë²”ìœ„ | **0.05 - 0.35** | ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ ì„ íƒ |
| ì¶œì²˜ ì œì•½ | `raw_note_id != raw_note_id` | ì„œë¡œ ë‹¤ë¥¸ ë©”ëª¨ì—ì„œë§Œ ì—°ê²° |
| Claude ì—­í•  | **ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„±** | ì˜ˆìƒ ë°– í†µì°° í‰ê°€ |
| í•„í„°ë§ | **threshold (min_score=65)** | ì–µì§€ ì—°ê²° ìë™ ì œê±° |

### Threshold íŒŒë¼ë¯¸í„° ì„¤ëª…
- **íƒ€ì…**: API Query íŒŒë¼ë¯¸í„° (ì‚¬ìš©ì ì¡°ì • ê°€ëŠ¥)
- **ê¸°ë³¸ê°’**: 65ì  (ì‹ ì„ í•˜ê³  í¥ë¯¸ë¡œìš´ ì—°ê²°)
- **ë²”ìœ„**: 0-100
- **ì—­í• **: Claude í‰ê°€ í›„ ì ìˆ˜ í•„í„°ë§
- **ì‚¬ìš©ë²•**:
  ```bash
  # ê¸°ë³¸ê°’ ì‚¬ìš©
  POST /pipeline/select-pairs

  # ë” ì—„ê²©í•˜ê²Œ (ë†’ì€ í’ˆì§ˆ)
  POST /pipeline/select-pairs?min_score=75

  # ë” ë„ˆê·¸ëŸ½ê²Œ (ë” ë§ì€ í›„ë³´)
  POST /pipeline/select-pairs?min_score=55
  ```
- **ì´ˆê¸° ìº˜ë¦¬ë¸Œë ˆì´ì…˜**: ì²« ì‹¤í–‰ í›„ ê²°ê³¼ ê²€í†  â†’ í•„ìš” ì‹œ ì¡°ì • (1íšŒ)
- **ì´í›„ ì‚¬ìš©**: ì¡°ì •í•œ ê°’ìœ¼ë¡œ ê³„ì† ìë™ ì‹¤í–‰ (ì¬ì¡°ì • ì„ íƒì )

### ì˜ˆìƒ íš¨ê³¼
1. **ë™ì¼ ì¶œì²˜ ìŒ ì œê±°**: "ê²Œì„..." ë©”ëª¨ ë‚´ Thought 8â†”9 ê°™ì€ ìŒ ìë™ ë°°ì œ
2. **ì„œë¡œ ë‹¤ë¥¸ ì•„ì´ë””ì–´ ì—°ê²°**: ìœ ì‚¬ë„ 0.18 = ê²Œì„+êµìœ¡, ì •ì›+ì†Œí”„íŠ¸ì›¨ì–´ ë“±
3. **ì–µì§€ ì—°ê²° í•„í„°ë§**: "ì•„ì¹¨ì‹ì‚¬+ë¸”ë™í™€" (15ì ) ìë™ ì œê±°
4. **ì°½ì˜ì  í†µì°° ë°œêµ´**: "ìƒíƒœê³„ ê· í˜•+ê²½ì œ ìˆœí™˜" (78ì ) ì„ íƒ

---

## ğŸ†• ìˆ˜ì •ëœ íŒŒì¼ ë° ë³€ê²½ ë‚´ì—­

### 1. `backend/docs/supabase_setup.sql`
- **ë³€ê²½**: `find_similar_pairs()` í•¨ìˆ˜ ìˆ˜ì •
- **ì¶”ê°€ ì¡°ê±´**: `AND a.raw_note_id != b.raw_note_id`
- **ê¸°ë³¸ê°’**: min_sim=0.05, max_sim=0.35

### 2. `backend/services/supabase_service.py`
- **ë³€ê²½**: `find_candidate_pairs()` ë©”ì„œë“œ ê¸°ë³¸ê°’
- **ì¶”ê°€ ë¡œì§**: ë™ì¼ ì¶œì²˜ ì œì™¸ í™•ì¸

### 3. `backend/services/ai_service.py`
- **ë³€ê²½**: `score_pairs()` í”„ë¡¬í”„íŠ¸ ì „ë©´ ì¬ì„¤ê³„
- **ìƒˆ í‰ê°€ ê¸°ì¤€**: ì°½ì˜ì  ì—°ê²° ê°€ëŠ¥ì„± (ì–µì§€ ì—°ê²° ê°ì§€)

### 4. `backend/routers/pipeline.py`
- **ë³€ê²½**: `/pipeline/select-pairs` ì—”ë“œí¬ì¸íŠ¸
- **ì¶”ê°€ íŒŒë¼ë¯¸í„°**: `min_score` (threshold)
- **ì¶”ê°€ ë¡œì§**: Fallback ì „ëµ, threshold í•„í„°ë§
- **ê¸°ë³¸ê°’**: min_similarity=0.05, max_similarity=0.35, min_score=65

### 5. `backend/schemas/zk.py`
- **ë³€ê²½ ì—†ìŒ** (ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥)
- **ì£¼ì˜**: `logical_expansion_score` í•„ë“œëª… ìœ ì§€ (ì‹¤ì œë¡œëŠ” "ì°½ì˜ì  ì—°ê²° ì ìˆ˜"ë¡œ í•´ì„)

---

## ğŸ“Œ MVP ì´í›„ ê°œì„  ì‚¬í•­

### ë‹¤ì¤‘ Pairs ì§€ì› (MVP+1)

**í˜„ì¬ (MVP)**: 1ê°œì˜ pair (2ê°œì˜ thought_unit)ë§Œ ì—°ê²°í•˜ì—¬ ì—ì„¸ì´ ìƒì„±

**ê°œì„  ë°©í–¥**: ì—¬ëŸ¬ pairsë¥¼ ë™ì‹œì— í™œìš©í•˜ì—¬ ë” í’ë¶€í•œ ê¸€ê° ìƒì„±

#### êµ¬í˜„ ì•„ì´ë””ì–´

##### 1. ë°ì´í„° êµ¬ì¡° ë³€ê²½
```sql
-- essays í…Œì´ë¸” í™•ì¥
ALTER TABLE essays ADD COLUMN pair_ids INTEGER[] DEFAULT '{}';
-- ê¸°ì¡´: pair_id INTEGER (ë‹¨ì¼)
-- ë³€ê²½: pair_ids INTEGER[] (ë°°ì—´)

-- ë˜ëŠ” ì—°ê²° í…Œì´ë¸” ìƒì„±
CREATE TABLE essay_pairs (
    essay_id INTEGER REFERENCES essays(id),
    pair_id INTEGER REFERENCES thought_pairs(id),
    sequence_order INTEGER,  -- ê¸€ ë‚´ ì‚¬ìš© ìˆœì„œ
    PRIMARY KEY (essay_id, pair_id)
);
```

##### 2. API íŒŒë¼ë¯¸í„° ì¶”ê°€
```python
@router.post("/generate-essays")
async def generate_essays(
    pair_count: int = Query(default=1, ge=1, le=5, description="ì‚¬ìš©í•  í˜ì–´ ê°œìˆ˜"),
    # pair_count=1: MVP (í˜„ì¬)
    # pair_count=2-3: ë‹¤ì¤‘ ê´€ì  ì—ì„¸ì´
    # pair_count=4-5: ë³µí•© ì£¼ì œ íƒêµ¬
    ...
):
```

##### 3. Claude í”„ë¡¬í”„íŠ¸ í™•ì¥
```python
# ë‹¨ì¼ pair (MVP)
system_message = """2ê°œì˜ ì‚¬ê³  ë‹¨ìœ„ë¥¼ ì—°ê²°í•˜ì—¬ ê¸€ê°ì„ ìƒì„±í•˜ì„¸ìš”."""

# ë‹¤ì¤‘ pairs (MVP+1)
system_message = """ë‹¤ìŒ {pair_count}ê°œì˜ ì‚¬ê³  ë‹¨ìœ„ ìŒë“¤ì„ ëª¨ë‘ í™œìš©í•˜ì—¬
í•˜ë‚˜ì˜ í†µí•©ëœ ê¸€ê°ì„ ìƒì„±í•˜ì„¸ìš”.

ê° ìŒì˜ ì—°ê²° ê´€ê³„ë¥¼ ê³ ë ¤í•˜ë©´ì„œ, ì „ì²´ì ìœ¼ë¡œ ì¼ê´€ëœ ì£¼ì œì™€ íë¦„ì„ êµ¬ì„±í•˜ì„¸ìš”.
- 2-3ê°œ ìŒ: ë‹¤ê°ë„ ë¶„ì„, ëŒ€ì¡°/ë¹„êµ
- 4-5ê°œ ìŒ: ì¢…í•©ì  íƒêµ¬, ì²´ê³„ì  ì „ê°œ
"""
```

##### 4. ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

**ì‹œë‚˜ë¦¬ì˜¤ A: ëŒ€ì¡°ì  ê´€ì  (2 pairs)**
- Pair 1: "ê²Œì„ ë‚œì´ë„" â†” "êµìœ¡ ìµœì  ë„ì „" (ìœ ì‚¬ë„ 0.18)
- Pair 2: "ëª°ì… ê²½í—˜" â†” "ì—…ë¬´ ìƒì‚°ì„±" (ìœ ì‚¬ë„ 0.22)
- â†’ ê¸€ê°: "í•™ìŠµê³¼ ì—…ë¬´ì—ì„œì˜ ìµœì  ë‚œì´ë„ ì„¤ê³„ ì›ì¹™"

**ì‹œë‚˜ë¦¬ì˜¤ B: ë‹¤ì¸µì  ë¶„ì„ (3 pairs)**
- Pair 1: "ì •ì› ê°€ê¾¸ê¸°" â†” "ì†Œí”„íŠ¸ì›¨ì–´ ë¦¬íŒ©í† ë§" (ìœ ì‚¬ë„ 0.15)
- Pair 2: "ìƒíƒœê³„ ê· í˜•" â†” "ì¡°ì§ ë¬¸í™”" (ìœ ì‚¬ë„ 0.19)
- Pair 3: "ì¥ê¸° íˆ¬ì" â†” "ê¸°ìˆ  ë¶€ì±„" (ìœ ì‚¬ë„ 0.21)
- â†’ ê¸€ê°: "ì§€ì† ê°€ëŠ¥í•œ ì„±ì¥ì˜ ê³µí†µ ì›ë¦¬: ìì—°, ì½”ë“œ, ì¡°ì§"

**ì‹œë‚˜ë¦¬ì˜¤ C: ì¢…í•©ì  íƒêµ¬ (5 pairs)**
- 5ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ í˜ì–´ë¥¼ ì—°ê²°
- â†’ ê¸€ê°: "ë³µì¡ê³„ ì´ë¡ ìœ¼ë¡œ ë°”ë¼ë³¸ ì°½ì˜ì„±ì˜ ë³¸ì§ˆ"

##### 5. êµ¬í˜„ ìš°ì„ ìˆœìœ„

**Phase 1 (MVP+1 ì´ˆê¸°)**
- 2-3 pairs ì§€ì› (ê°€ì¥ ìˆ˜ìš” ë†’ìŒ)
- essay_pairs ì—°ê²° í…Œì´ë¸” ìƒì„±
- generate_essays ì—”ë“œí¬ì¸íŠ¸ì— pair_count íŒŒë¼ë¯¸í„° ì¶”ê°€
- Claude í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™•ì¥

**Phase 2 (MVP+2)**
- 4-5 pairs ì§€ì› (ë³µì¡í•œ ê¸€ê°)
- Pair ê°„ ì—°ê²°ì„± ìë™ ë¶„ì„ (graph-based)
- ìµœì  ì¡°í•© ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜

**Phase 3 (MVP+3)**
- ì‚¬ìš©ì ì •ì˜ pair ì¡°í•© ì„ íƒ UI
- Pair ë°°ì¹˜ ìˆœì„œ ìµœì í™”
- ê¸€ê° ë³µì¡ë„ ë©”íŠ¸ë¦­ ì œê³µ

#### ê¸°ìˆ ì  ê³ ë ¤ì‚¬í•­

**Claude API í† í° ì œí•œ**
- 1 pair: ~500 tokens input
- 5 pairs: ~2500 tokens input
- ëŒ€ì‘: ë°°ì¹˜ í¬ê¸° ì¡°ì •, ìš”ì•½ ì „ì²˜ë¦¬

**DB ì¿¼ë¦¬ ì„±ëŠ¥**
- ë‹¤ì¤‘ pair ì¡°íšŒ ì‹œ JOIN ìµœì í™”
- ì¸ë±ìŠ¤: `(is_used_in_essay, similarity_score)`

**ì‚¬ìš©ì ê²½í—˜**
- ê¸°ë³¸ê°’ì€ 1 pair (ë‹¨ìˆœí•¨ ìœ ì§€)
- ê³ ê¸‰ ì‚¬ìš©ìì—ê²Œë§Œ ë‹¤ì¤‘ pair ì˜µì…˜ ë…¸ì¶œ
- ë³µì¡ë„ ê²½ê³ : "3ê°œ ì´ìƒ pairëŠ” ê¸€ êµ¬ì„±ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤"

#### ì˜ˆìƒ íš¨ê³¼

**ì¥ì **
1. ë” í’ë¶€í•˜ê³  ë‹¤ì¸µì ì¸ ê¸€ê° ìƒì„±
2. ì—¬ëŸ¬ ë„ë©”ì¸ ì§€ì‹ì˜ ìœµí•©
3. ì°½ì˜ì  í†µì°°ì˜ í­ í™•ëŒ€

**ë‹¨ì **
1. ê¸€ê° ë³µì¡ë„ ì¦ê°€ (ì´ˆë³´ì ì§„ì…ì¥ë²½)
2. Claude ë¹„ìš© ì¦ê°€ (í† í° ì‚¬ìš©ëŸ‰ 2-5ë°°)
3. ê¸€ ì¼ê´€ì„± ìœ ì§€ ì–´ë ¤ì›€

**ê¶Œì¥ ì‚¬ìš©ë²•**
- ê¸°ë³¸: 1 pair (MVP)
- ì¤‘ê¸‰: 2-3 pairs (ë‹¤ê°ë„ ë¶„ì„)
- ê³ ê¸‰: 4-5 pairs (ë³µí•© ì£¼ì œ íƒêµ¬)

---

**Step 3 ì™„ë£Œ! ë‹¤ìŒì€ Step 4 êµ¬í˜„ì…ë‹ˆë‹¤.**

---
---

# Step 4 (Essay ìƒì„±) êµ¬í˜„ ê³„íš

## ëª©í‘œ
thought_pairsì—ì„œ ë¯¸ì‚¬ìš© í˜ì–´ë¥¼ ì¡°íšŒí•˜ê³ , Claudeë¡œ ì—ì„¸ì´ ê¸€ê°(title, 3ë‹¨ outline, reason)ì„ ìƒì„±í•˜ì—¬ essays í…Œì´ë¸”ì— ì €ì¥

## í˜„ì¬ ìƒíƒœ

### âœ… Step 3 ì™„ë£Œ ìƒíƒœ
- **thought_pairs**: 10ê°œ ì €ì¥ë¨ (ID 1-10)
- **ëª¨ë“  í˜ì–´**: is_used_in_essay = FALSE (ë¯¸ì‚¬ìš© ìƒíƒœ)
- **ìœ ì‚¬ë„ ë²”ìœ„**: 0.29-0.34 (ë‚®ì€ ìœ ì‚¬ë„, ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸)
- **ì°½ì˜ì  ì—°ê²° ì ìˆ˜**: 71-76ì  (threshold 65 í†µê³¼)
- **ë™ì¼ ì¶œì²˜ ì œì™¸**: ëª¨ë“  í˜ì–´ê°€ ì„œë¡œ ë‹¤ë¥¸ raw_noteì—ì„œ ìƒì„±ë¨

### ğŸ“Š í˜„ì¬ ë°ì´í„° í˜„í™©
- **raw_notes**: 5ê°œ
- **thought_units**: 11ê°œ (ëª¨ë‘ embedding ìƒì„±ë¨)
- **thought_pairs**: 10ê°œ (ëª¨ë‘ is_used_in_essay = FALSE)
- **essays**: 0ê°œ (Step 4 êµ¬í˜„ ëŒ€ê¸°)

### âœ… ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…
1. **schemas/essay.py**: ëª¨ë“  Pydantic ëª¨ë¸ ì™„ì„± (71 ë¼ì¸)
   - UsedThought, EssayCreate, EssayDB, EssayResponse, EssayListResponse
2. **supabase_service.pyì˜ get_pair_with_thoughts()**: ì™„ì„±ë¨ (Lines 520-621)
   - í˜ì–´ + ì–‘ìª½ thought_units + raw_notes JOIN ì¡°íšŒ
   - Step 4ì—ì„œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥

## Step 4 ì•Œê³ ë¦¬ì¦˜

### 1. ë¯¸ì‚¬ìš© í˜ì–´ ì¡°íšŒ
- `get_unused_thought_pairs(limit=10)` ì‚¬ìš©
- is_used_in_essay = FALSE ì¡°ê±´
- ê¸°ë³¸ì ìœ¼ë¡œ ìµœëŒ€ 10ê°œ ì¡°íšŒ (ì‚¬ìš©ì ì¡°ì • ê°€ëŠ¥)

### 2. ê° í˜ì–´ì— ëŒ€í•´ ì—ì„¸ì´ ìƒì„±
- `get_pair_with_thoughts(pair_id)` í˜¸ì¶œí•˜ì—¬ ì „ì²´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
  - thought_a (claim, context, source_title, source_url)
  - thought_b (claim, context, source_title, source_url)
  - similarity_score, connection_reason
- Claude Sonnet 4.5ì— ì „ë‹¬:
  - **Input**: 2ê°œì˜ ì‚¬ê³  ë‹¨ìœ„ (claim + context + ì¶œì²˜)
  - **Output**: Essay (title, outline[3], reason)
- Pydantic ê²€ì¦ (EssayCreate ëª¨ë¸)

### 3. DB ì €ì¥ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
- essays í…Œì´ë¸”ì— ì €ì¥ (JSONB ì§ë ¬í™”)
- thought_pairs.is_used_in_essay = TRUE ì—…ë°ì´íŠ¸
- CASCADE delete ë³´ì¥ (pair ì‚­ì œ ì‹œ essayë„ ì‚­ì œ)

---

## ì „ì œ ì¡°ê±´: essays í…Œì´ë¸” ìƒì„± í™•ì¸

### âœ… DB ìŠ¤í‚¤ë§ˆ í™•ì¸ ì™„ë£Œ
`backend/docs/supabase_setup.sql` (Lines 57-68)ì— essays í…Œì´ë¸”ì´ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

```sql
CREATE TABLE IF NOT EXISTS essays (
    id SERIAL PRIMARY KEY,
    type TEXT DEFAULT 'essay',
    title TEXT NOT NULL,
    outline JSONB NOT NULL,
    used_thoughts_json JSONB NOT NULL,
    reason TEXT NOT NULL,
    pair_id INTEGER NOT NULL REFERENCES thought_pairs(id) ON DELETE CASCADE,
    generated_at TIMESTAMPTZ DEFAULT NOW()
);
CREATE INDEX IF NOT EXISTS idx_essays_generated_at ON essays(generated_at DESC);
```

### í…Œì´ë¸” ìƒì„± í™•ì¸ ë°©ë²•
Step 4 êµ¬í˜„ ì „ì— Supabaseì—ì„œ essays í…Œì´ë¸”ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸:

```sql
-- í…Œì´ë¸” ì¡´ì¬ í™•ì¸
SELECT EXISTS (
    SELECT FROM information_schema.tables
    WHERE table_name = 'essays'
);

-- í…Œì´ë¸” êµ¬ì¡° í™•ì¸
\d essays

-- ë˜ëŠ” ì»¬ëŸ¼ ì •ë³´ í™•ì¸
SELECT column_name, data_type, is_nullable
FROM information_schema.columns
WHERE table_name = 'essays'
ORDER BY ordinal_position;
```

**ë§Œì•½ í…Œì´ë¸”ì´ ì—†ë‹¤ë©´:**
1. Supabase Dashboard â†’ SQL Editor
2. `backend/docs/supabase_setup.sql` ì „ì²´ ë‚´ìš© ë³µì‚¬
3. ì‹¤í–‰ (CREATE TABLE IF NOT EXISTSì´ë¯€ë¡œ ì¤‘ë³µ ìƒì„± ê±±ì • ì—†ìŒ)

---

## êµ¬í˜„ ê³„íš

### Phase 1: AI Service í™•ì¥

#### íŒŒì¼: `backend/services/ai_service.py` (í™•ì¥)

**ìƒˆ ë©”ì„œë“œ ì¶”ê°€:**

##### `generate_essay()` - ì—ì„¸ì´ ê¸€ê° ìƒì„±
```python
async def generate_essay(
    self,
    pair_data: dict,
) -> dict:
    """
    ë‹¨ì¼ í˜ì–´ë¡œë¶€í„° ì—ì„¸ì´ ê¸€ê° ìƒì„±.

    Args:
        pair_data: get_pair_with_thoughts() ê²°ê³¼
            {
                "pair_id": int,
                "similarity_score": float,
                "connection_reason": str,
                "thought_a": {
                    "id": int,
                    "claim": str,
                    "context": str | None,
                    "source_title": str,
                    "source_url": str
                },
                "thought_b": { ... }
            }

    Returns:
        {
            "title": str,  # 5-100ì
            "outline": [str, str, str],  # ì •í™•íˆ 3ê°œ
            "reason": str,  # ìµœëŒ€ 300ì
            "used_thoughts": [
                {
                    "thought_id": int,
                    "claim": str,
                    "source_title": str,
                    "source_url": str
                }
            ]
        }

    Raises:
        ValueError: Claude ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨
        ValidationError: Pydantic ê²€ì¦ ì‹¤íŒ¨
    """
```

**í”„ë¡¬í”„íŠ¸ ì„¤ê³„:**
```python
system_message = """ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ê¸€ê°ì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì‚¬ê³  ë‹¨ìœ„(thought unit)ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì´ë“¤ì„ ì—°ê²°í•˜ì—¬ ì‹ ì„ í•˜ê³  í¥ë¯¸ë¡œìš´ ê¸€ê°(essay prompt)ì„ ìƒì„±í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:
1. **ì œëª© (title)**: ê¸€ê°ì˜ í•µì‹¬ì„ ë‹´ì€ ì œëª© (5-100ì)
   - ë‘ ì•„ì´ë””ì–´ì˜ ì—°ê²°ì„ ì•”ì‹œí•˜ë˜, ë„ˆë¬´ ì§ì„¤ì ì´ì§€ ì•Šê²Œ
   - í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì œëª©

2. **3ë‹¨ ê°œìš” (outline)**: ê¸€ì˜ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 3ê°œ ë¬¸ì¥
   - 1ë‹¨: ì²« ë²ˆì§¸ ì‚¬ê³  ë‹¨ìœ„ ì†Œê°œ ë˜ëŠ” ë°°ê²½ ì„¤ì •
   - 2ë‹¨: ë‘ ë²ˆì§¸ ì‚¬ê³  ë‹¨ìœ„ ë„ì… ë° ì—°ê²°ì  íƒìƒ‰
   - 3ë‹¨: í†µí•©ëœ í†µì°° ë˜ëŠ” ìƒˆë¡œìš´ ì§ˆë¬¸ ì œì‹œ
   - ê° ë¬¸ì¥ì€ 50-200ì

3. **ì´ ì¡°í•©ì„ ì„ íƒí•œ ì´ìœ  (reason)**: ì™œ ì´ ë‘ ì•„ì´ë””ì–´ë¥¼ ì—°ê²°í•˜ë©´ í¥ë¯¸ë¡œìš´ ê¸€ì´ ë‚˜ì˜¬ì§€ ì„¤ëª… (50-300ì)
   - ë…ìê°€ ì–»ì„ ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì‹œê°
   - ë‘ ë„ë©”ì¸ì˜ ì˜ì™¸ì˜ ì—°ê²°ì 

ì¤‘ìš” ì›ì¹™:
- ì–µì§€ ì—°ê²° ì§€ì–‘: ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ ìœ ì§€
- êµ¬ì²´ì  ì˜ˆì‹œ: ì¶”ìƒì  ê°œë…ë§Œ ë‚˜ì—´í•˜ì§€ ë§ê³  êµ¬ì²´ì  ìƒí™© ì œì‹œ
- ë…ì ì¤‘ì‹¬: ì‹¤ì œë¡œ ì½ê³  ì‹¶ì€ ê¸€ê°ì¸ì§€ ê³ ë ¤
"""

prompt = f"""ë‹¤ìŒ ë‘ ì‚¬ê³  ë‹¨ìœ„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸€ê°ì„ ìƒì„±í•˜ì„¸ìš”.

**Thought A** (ì¶œì²˜: {source_title_a})
- Claim: {claim_a}
- Context: {context_a or "ì—†ìŒ"}
- ì¶œì²˜ URL: {source_url_a}

**Thought B** (ì¶œì²˜: {source_title_b})
- Claim: {claim_b}
- Context: {context_b or "ì—†ìŒ"}
- ì¶œì²˜ URL: {source_url_b}

**ë‘ ì•„ì´ë””ì–´ì˜ ì—°ê²° ì´ìœ ** (Step 3ì—ì„œ í‰ê°€):
{connection_reason}

**ìœ ì‚¬ë„**: {similarity_score:.3f} (ë‚®ì€ ê°’ = ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸)

---

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "title": "ê¸€ê° ì œëª© (5-100ì)",
  "outline": [
    "1ë‹¨: ì²« ë²ˆì§¸ ì•„ì´ë””ì–´ ì†Œê°œ...",
    "2ë‹¨: ë‘ ë²ˆì§¸ ì•„ì´ë””ì–´ì™€ ì—°ê²°...",
    "3ë‹¨: í†µí•©ëœ í†µì°°..."
  ],
  "reason": "ì´ ì¡°í•©ì„ ì„ íƒí•œ ì´ìœ  (50-300ì)"
}}

ì¤‘ìš”:
- outlineì€ ì •í™•íˆ 3ê°œ ë¬¸ì¥
- reasonì€ í•œ ì¤„ë¡œ ì‘ì„± (ì¤„ë°”ê¿ˆ ê¸ˆì§€)
- JSONë§Œ ë°˜í™˜
"""
```

**êµ¬í˜„ íŒ¨í„´** (ê¸°ì¡´ ë©”ì„œë“œ ì°¸ê³ ):
1. `generate_content_with_claude()` í˜¸ì¶œ
2. `safe_json_parse()` ë¡œ ì‘ë‹µ íŒŒì‹±
3. Pydantic ê²€ì¦ (EssayCreate ëª¨ë¸)
4. used_thoughts ë¦¬ìŠ¤íŠ¸ ìƒì„±
5. ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

**ì—ëŸ¬ ì²˜ë¦¬**:
- JSON íŒŒì‹± ì‹¤íŒ¨ â†’ ValueError with raw content
- Pydantic ê²€ì¦ ì‹¤íŒ¨ â†’ ValidationError with details
- Claude API ì‹¤íŒ¨ â†’ Exception with error message

**ì¶”ê°€ ë¼ì¸ ìˆ˜ ì˜ˆìƒ:** ~120 ë¼ì¸

---

### Phase 2: Supabase Service í™•ì¥

#### íŒŒì¼: `backend/services/supabase_service.py` (í™•ì¥)

**ìƒˆ ë©”ì„œë“œ ì¶”ê°€:**

##### 1. `insert_essay()` - ë‹¨ì¼ ì—ì„¸ì´ ì €ì¥
```python
async def insert_essay(self, essay: EssayCreate) -> dict:
    """
    essays í…Œì´ë¸”ì— ë‹¨ì¼ ì—ì„¸ì´ ì €ì¥.

    Args:
        essay: EssayCreate ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤

    Returns:
        {
            "id": int,
            "type": str,
            "title": str,
            "outline": list[str],
            "used_thoughts_json": list[dict],
            "reason": str,
            "pair_id": int,
            "generated_at": str (ISO format)
        }

    Raises:
        Exception: DB ì €ì¥ ì‹¤íŒ¨ ì‹œ
    """
    await self._ensure_initialized()

    try:
        # JSONB í•„ë“œ ì§ë ¬í™”
        essay_dict = {
            "type": essay.type,
            "title": essay.title,
            "outline": essay.outline,  # list â†’ JSONB
            "used_thoughts_json": [t.model_dump() for t in essay.used_thoughts],  # JSONB
            "reason": essay.reason,
            "pair_id": essay.pair_id
        }

        response = await self.client.table("essays")\
            .insert(essay_dict)\
            .execute()

        inserted = response.data[0]
        logger.info(f"Inserted essay ID {inserted['id']} for pair {essay.pair_id}")
        return inserted

    except Exception as e:
        logger.error(f"Failed to insert essay: {e}")
        raise
```

##### 2. `insert_essays_batch()` - ë°°ì¹˜ ì €ì¥
```python
async def insert_essays_batch(self, essays: List[EssayCreate]) -> List[dict]:
    """
    ì—¬ëŸ¬ ì—ì„¸ì´ ë°°ì¹˜ ì €ì¥.

    Args:
        essays: EssayCreate ëª¨ë¸ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì €ì¥ëœ ì—ì„¸ì´ ë¦¬ìŠ¤íŠ¸

    Note:
        - UPSERTëŠ” í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€ëŠ” pair_id ì™¸ë˜í‚¤ë¡œ ë³´ì¥)
        - ì‹¤íŒ¨ ì‹œ ì „ì²´ ë¡¤ë°±
    """
    await self._ensure_initialized()

    if not essays:
        return []

    try:
        essays_dict = [
            {
                "type": e.type,
                "title": e.title,
                "outline": e.outline,
                "used_thoughts_json": [t.model_dump() for t in e.used_thoughts],
                "reason": e.reason,
                "pair_id": e.pair_id
            }
            for e in essays
        ]

        response = await self.client.table("essays")\
            .insert(essays_dict)\
            .execute()

        inserted = response.data
        logger.info(f"Batch inserted {len(inserted)} essays")
        return inserted

    except Exception as e:
        logger.error(f"Failed to batch insert essays: {e}")
        raise
```

##### 3. `get_essays()` - ì—ì„¸ì´ ëª©ë¡ ì¡°íšŒ
```python
async def get_essays(
    self,
    limit: int = 10,
    offset: int = 0,
    order_by: str = "generated_at.desc"
) -> List[dict]:
    """
    essays í…Œì´ë¸” ì¡°íšŒ (ìµœì‹ ìˆœ).

    Args:
        limit: ìµœëŒ€ ë°˜í™˜ ê°œìˆ˜ (ê¸°ë³¸ 10)
        offset: ê±´ë„ˆë›¸ ê°œìˆ˜ (í˜ì´ì§€ë„¤ì´ì…˜)
        order_by: ì •ë ¬ ê¸°ì¤€ (ê¸°ë³¸ "generated_at.desc")

    Returns:
        ì—ì„¸ì´ ë¦¬ìŠ¤íŠ¸ (JSONB í•„ë“œ ìë™ íŒŒì‹±ë¨)
    """
    await self._ensure_initialized()

    try:
        response = await self.client.table("essays")\
            .select("*")\
            .order(order_by)\
            .limit(limit)\
            .offset(offset)\
            .execute()

        essays = response.data
        logger.info(f"Retrieved {len(essays)} essays")
        return essays

    except Exception as e:
        logger.error(f"Failed to get essays: {e}")
        raise
```

##### 4. `get_essay_by_id()` - ë‹¨ì¼ ì—ì„¸ì´ ì¡°íšŒ
```python
async def get_essay_by_id(self, essay_id: int) -> dict:
    """
    ë‹¨ì¼ ì—ì„¸ì´ ì¡°íšŒ.

    Args:
        essay_id: ì—ì„¸ì´ ID

    Returns:
        ì—ì„¸ì´ ë°ì´í„°

    Raises:
        Exception: ì—ì„¸ì´ê°€ ì—†ê±°ë‚˜ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ
    """
    await self._ensure_initialized()

    try:
        response = await self.client.table("essays")\
            .select("*")\
            .eq("id", essay_id)\
            .single()\
            .execute()

        essay = response.data
        logger.info(f"Retrieved essay ID {essay_id}")
        return essay

    except Exception as e:
        logger.error(f"Failed to get essay {essay_id}: {e}")
        raise
```

**ì¶”ê°€ ë¼ì¸ ìˆ˜ ì˜ˆìƒ:** ~150 ë¼ì¸

---

### Phase 3: Pipeline ë¼ìš°í„° í™•ì¥

#### íŒŒì¼: `backend/routers/pipeline.py` (í™•ì¥)

**ìƒˆ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€:**

##### 1. `POST /pipeline/generate-essays` - Step 4 ì‹¤í–‰
```python
@router.post("/generate-essays")
async def generate_essays(
    max_pairs: int = Query(default=5, ge=1, le=10, description="ì²˜ë¦¬í•  ìµœëŒ€ í˜ì–´ ê°œìˆ˜"),
    supabase_service: SupabaseService = Depends(get_supabase_service),
    ai_service: AIService = Depends(get_ai_service),
):
    """
    Step 4: Essay ê¸€ê° ìƒì„±

    í”„ë¡œì„¸ìŠ¤:
    1. get_unused_thought_pairs()ë¡œ ë¯¸ì‚¬ìš© í˜ì–´ ì¡°íšŒ
    2. ê° í˜ì–´ì— ëŒ€í•´:
       a. get_pair_with_thoughts()ë¡œ ì „ì²´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
       b. ai_service.generate_essay()ë¡œ Claude í˜¸ì¶œ
       c. ì—ì„¸ì´ ìƒì„± (title, outline, reason)
    3. insert_essays_batch()ë¡œ ë°°ì¹˜ ì €ì¥
    4. ê° í˜ì–´ì˜ is_used_in_essay = TRUE ì—…ë°ì´íŠ¸
    5. ìƒì„±ëœ ì—ì„¸ì´ ëª©ë¡ ë°˜í™˜

    Args:
        max_pairs: ì²˜ë¦¬í•  ìµœëŒ€ í˜ì–´ ê°œìˆ˜ (ê¸°ë³¸ 5, ìµœëŒ€ 10)

    Returns:
        {
            "success": true,
            "pairs_processed": 5,
            "essays_generated": 5,
            "essays": [
                {
                    "id": 1,
                    "title": "...",
                    "outline": ["...", "...", "..."],
                    "reason": "...",
                    "pair_id": 1,
                    "used_thoughts": [...]
                }
            ],
            "errors": []
        }

    Note:
        - ë¶€ë¶„ ì„±ê³µ í—ˆìš©: ì¼ë¶€ í˜ì–´ ì‹¤íŒ¨í•´ë„ ì„±ê³µí•œ ê²ƒì€ ì €ì¥
        - ê° í˜ì–´ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ (í•œ í˜ì–´ ì‹¤íŒ¨ê°€ ë‹¤ë¥¸ í˜ì–´ì— ì˜í–¥ ì—†ìŒ)
    """
    result = {
        "success": False,
        "pairs_processed": 0,
        "essays_generated": 0,
        "essays": [],
        "errors": [],
    }

    try:
        # 1. ë¯¸ì‚¬ìš© í˜ì–´ ì¡°íšŒ
        logger.info(f"Step 4: Fetching up to {max_pairs} unused pairs...")
        unused_pairs = await supabase_service.get_unused_thought_pairs(limit=max_pairs)

        if not unused_pairs:
            logger.warning("No unused pairs found")
            result["errors"].append("No unused pairs available. Run Step 3 first.")
            return result

        logger.info(f"Found {len(unused_pairs)} unused pairs")

        # 2. ê° í˜ì–´ì— ëŒ€í•´ ì—ì„¸ì´ ìƒì„±
        generated_essays: List[EssayCreate] = []
        processed_pair_ids: List[int] = []

        for pair in unused_pairs:
            pair_id = pair["id"]
            try:
                result["pairs_processed"] += 1

                # 2a. í˜ì–´ ì „ì²´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                pair_data = await supabase_service.get_pair_with_thoughts(pair_id)

                # 2b. Claudeë¡œ ì—ì„¸ì´ ìƒì„±
                logger.info(f"Generating essay for pair {pair_id}...")
                essay_dict = await ai_service.generate_essay(pair_data)

                # 2c. EssayCreate ëª¨ë¸ ìƒì„±
                essay = EssayCreate(
                    title=essay_dict["title"],
                    outline=essay_dict["outline"],
                    used_thoughts=essay_dict["used_thoughts"],
                    reason=essay_dict["reason"],
                    pair_id=pair_id
                )

                generated_essays.append(essay)
                processed_pair_ids.append(pair_id)
                logger.info(f"âœ“ Essay generated for pair {pair_id}: {essay.title[:50]}...")

            except Exception as e:
                error_msg = f"Failed to generate essay for pair {pair_id}: {str(e)}"
                logger.error(error_msg)
                result["errors"].append(error_msg)
                # ê³„ì† ì§„í–‰ (ë¶€ë¶„ ì„±ê³µ í—ˆìš©)

        # 3. ìƒì„±ëœ ì—ì„¸ì´ ë°°ì¹˜ ì €ì¥
        if generated_essays:
            logger.info(f"Saving {len(generated_essays)} essays to DB...")
            saved_essays = await supabase_service.insert_essays_batch(generated_essays)
            result["essays_generated"] = len(saved_essays)
            result["essays"] = saved_essays

            # 4. ì‚¬ìš©ëœ í˜ì–´ ìƒíƒœ ì—…ë°ì´íŠ¸
            logger.info("Updating pair usage status...")
            for pair_id in processed_pair_ids:
                try:
                    await supabase_service.update_pair_used_status(pair_id, is_used=True)
                except Exception as e:
                    logger.error(f"Failed to update pair {pair_id} status: {e}")
                    # ì—ëŸ¬ ë¬´ì‹œ (ì—ì„¸ì´ëŠ” ì´ë¯¸ ì €ì¥ë¨)

            logger.info(f"âœ“ Step 4 completed: {len(saved_essays)} essays generated")
            result["success"] = True
        else:
            logger.warning("No essays were successfully generated")
            result["errors"].append("All essay generation attempts failed")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Step 4 failed: {e}", exc_info=True)
        result["errors"].append(f"Pipeline error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

    return result
```

##### 2. `GET /pipeline/essays` - ì—ì„¸ì´ ëª©ë¡ ì¡°íšŒ
```python
@router.get("/essays")
async def get_essays_list(
    limit: int = Query(default=10, ge=1, le=100, description="ìµœëŒ€ ë°˜í™˜ ê°œìˆ˜"),
    offset: int = Query(default=0, ge=0, description="ê±´ë„ˆë›¸ ê°œìˆ˜"),
    supabase_service: SupabaseService = Depends(get_supabase_service),
):
    """
    ì €ì¥ëœ ì—ì„¸ì´ ëª©ë¡ ì¡°íšŒ (ìµœì‹ ìˆœ).

    Args:
        limit: ìµœëŒ€ ë°˜í™˜ ê°œìˆ˜ (ê¸°ë³¸ 10)
        offset: ê±´ë„ˆë›¸ ê°œìˆ˜ (í˜ì´ì§€ë„¤ì´ì…˜)

    Returns:
        {
            "total": int,
            "essays": [...]
        }
    """
    try:
        essays = await supabase_service.get_essays(limit=limit, offset=offset)

        # TODO: total count ì¿¼ë¦¬ ì¶”ê°€ (í˜„ì¬ëŠ” ë°˜í™˜ëœ ê°œìˆ˜ë¡œ ëŒ€ì²´)
        return {
            "total": len(essays),
            "essays": essays
        }

    except Exception as e:
        logger.error(f"Failed to get essays: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

##### 3. `POST /pipeline/run-all` - ì „ì²´ íŒŒì´í”„ë¼ì¸ (Step 1-4, í™•ì¥)
```python
@router.post("/run-all")
async def run_all_pipeline(
    # Step 1 params
    page_size: int = Query(default=100, ge=1, le=100),
    # Step 3 params
    min_similarity: float = Query(default=0.05, ge=0, le=1),
    max_similarity: float = Query(default=0.35, ge=0, le=1),
    min_score: int = Query(default=65, ge=0, le=100),
    top_n: int = Query(default=5, ge=1, le=20),
    # Step 4 params (ìƒˆë¡œ ì¶”ê°€)
    max_essay_pairs: int = Query(default=5, ge=1, le=10, description="ì—ì„¸ì´ ìƒì„±í•  í˜ì–´ ê°œìˆ˜"),
    supabase_service: SupabaseService = Depends(get_supabase_service),
    notion_service: NotionService = Depends(get_notion_service),
    ai_service: AIService = Depends(get_ai_service),
):
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: Step 1 â†’ Step 2 â†’ Step 3 â†’ Step 4

    Returns:
        {
            "success": bool,
            "step1_imported": int,
            "step2_thoughts": int,
            "step3_pairs": int,
            "step4_essays": int,  # ìƒˆë¡œ ì¶”ê°€
            "errors": [...]
        }
    """
    result = {
        "success": False,
        "step1_imported": 0,
        "step2_thoughts": 0,
        "step3_pairs": 0,
        "step4_essays": 0,  # ìƒˆë¡œ ì¶”ê°€
        "errors": [],
    }

    try:
        # Step 1-3 (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        # ...

        # Step 4: Essay ìƒì„± (ìƒˆë¡œ ì¶”ê°€)
        logger.info("Starting Step 4: Essay generation...")
        essay_result = await generate_essays(
            max_pairs=max_essay_pairs,
            supabase_service=supabase_service,
            ai_service=ai_service
        )

        result["step4_essays"] = essay_result["essays_generated"]
        result["errors"].extend(essay_result["errors"])

        # ì „ì²´ ì„±ê³µ íŒë‹¨
        if result["step4_essays"] > 0:
            result["success"] = True
            logger.info(f"âœ“ Full pipeline completed: {result['step4_essays']} essays generated")
        else:
            logger.warning("Pipeline completed but no essays generated")

    except Exception as e:
        logger.error(f"Pipeline failed: {e}", exc_info=True)
        result["errors"].append(f"Pipeline error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

    return result
```

**ì¶”ê°€ ë¼ì¸ ìˆ˜ ì˜ˆìƒ:** ~250 ë¼ì¸

---

## êµ¬í˜„ íŒŒì¼ ìš”ì•½

| íŒŒì¼ | ì‘ì—… | ì˜ˆìƒ ë¼ì¸ ìˆ˜ |
|------|------|-------------|
| `backend/schemas/essay.py` | âœ… ì´ë¯¸ ì™„ì„± | 0 ë¼ì¸ (ë³€ê²½ ì—†ìŒ) |
| `backend/services/ai_service.py` | 1ê°œ ë©”ì„œë“œ ì¶”ê°€ (generate_essay) | +120 ë¼ì¸ |
| `backend/services/supabase_service.py` | 4ê°œ ë©”ì„œë“œ ì¶”ê°€ (essay CRUD) | +150 ë¼ì¸ |
| `backend/routers/pipeline.py` | 2ê°œ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€, 1ê°œ í™•ì¥ | +250 ë¼ì¸ |
| **í•©ê³„** | | **~520 ë¼ì¸** |

---

## í…ŒìŠ¤íŠ¸ ê³„íš

### 1. ë¯¸ì‚¬ìš© í˜ì–´ í™•ì¸ (ì‹¤í–‰ ì „)
```sql
-- í˜„ì¬ ë¯¸ì‚¬ìš© í˜ì–´ ìƒíƒœ
SELECT
    id,
    thought_a_id,
    thought_b_id,
    similarity_score,
    is_used_in_essay,
    LEFT(connection_reason, 50) as reason_preview
FROM thought_pairs
WHERE is_used_in_essay = FALSE
ORDER BY similarity_score DESC;
```

### 2. Step 4 ì‹¤í–‰
```bash
# ê¸°ë³¸ê°’ ì‚¬ìš© (ìµœëŒ€ 5ê°œ í˜ì–´)
curl -X POST "http://localhost:8000/pipeline/generate-essays"

# ë” ë§ì€ í˜ì–´ ì²˜ë¦¬ (ìµœëŒ€ 10ê°œ)
curl -X POST "http://localhost:8000/pipeline/generate-essays?max_pairs=10"

# ì—ì„¸ì´ ëª©ë¡ ì¡°íšŒ
curl "http://localhost:8000/pipeline/essays?limit=10"
```

### 3. ê²°ê³¼ ê²€ì¦
```sql
-- ìƒì„±ëœ ì—ì„¸ì´ í™•ì¸
SELECT
    e.id,
    e.title,
    e.outline,
    e.reason,
    e.pair_id,
    e.generated_at,
    tp.similarity_score,
    tp.is_used_in_essay
FROM essays e
JOIN thought_pairs tp ON e.pair_id = tp.id
ORDER BY e.generated_at DESC;

-- ì‚¬ìš©ëœ í˜ì–´ í™•ì¸
SELECT
    COUNT(*) FILTER (WHERE is_used_in_essay = TRUE) as used_pairs,
    COUNT(*) FILTER (WHERE is_used_in_essay = FALSE) as unused_pairs,
    COUNT(*) as total_pairs
FROM thought_pairs;
```

### 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
```bash
# Step 1-4 ì „ì²´ ì‹¤í–‰
curl -X POST "http://localhost:8000/pipeline/run-all?max_essay_pairs=5"
```

---

## ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

### Claude API í˜¸ì¶œ ìµœì í™”
- ìˆœì°¨ ì²˜ë¦¬ (ë°°ì¹˜ ì²˜ë¦¬ ë¶ˆê°€, ê° í˜ì–´ë§ˆë‹¤ ë…ë¦½ì  í”„ë¡¬í”„íŠ¸)
- Rate limiting ì¤€ìˆ˜ (5 req/sec)
- ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 5ê°œ í˜ì–´ = ì•½ 10-15ì´ˆ
- í† í° ì‚¬ìš©ëŸ‰: ~800-1200 tokens per request

### ë¶€ë¶„ ì„±ê³µ ì „ëµ
- ì¼ë¶€ í˜ì–´ ì‹¤íŒ¨í•´ë„ ì„±ê³µí•œ ê²ƒì€ ì €ì¥
- ì—ëŸ¬ ë¡œê¹… ë° ì‚¬ìš©ìì—ê²Œ ë³´ê³ 
- ì‹¤íŒ¨í•œ í˜ì–´ëŠ” is_used_in_essay = FALSE ìœ ì§€ (ì¬ì‹œë„ ê°€ëŠ¥)

### JSONB í•„ë“œ ì²˜ë¦¬
- outline: list[str] â†’ JSONB (ìë™ ì§ë ¬í™”)
- used_thoughts_json: list[dict] â†’ JSONB (model_dump() ì‚¬ìš©)
- ì¡°íšŒ ì‹œ ìë™ íŒŒì‹±ë¨ (Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì²˜ë¦¬)

---

## ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (ì„ì‹œ íŒŒì¼)

ì‹¤í–‰ í›„ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ `temp/verification/`ì— ìƒì„±:

### `temp/verification/verify_step4.py`
```python
"""
Step 4 ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

essays í…Œì´ë¸” ë°ì´í„°ë¥¼ ìƒì„¸ ë¶„ì„í•˜ì—¬ Step 4 ì™„ë£Œ í™•ì¸
"""

import asyncio
import sys
from pathlib import Path
from dotenv import load_dotenv

# Add backend to path
backend_path = Path(__file__).parent.parent.parent / "backend"
sys.path.insert(0, str(backend_path))

# Load environment variables
env_path = backend_path / ".env"
load_dotenv(env_path)

from services.supabase_service import SupabaseService


async def main():
    """Step 4 ê²€ì¦"""
    print("=" * 70)
    print("Step 4 ê²€ì¦: essays í…Œì´ë¸” ë°ì´í„° ë¶„ì„")
    print("=" * 70)

    supabase = SupabaseService()
    await supabase._ensure_initialized()

    try:
        # 1. essays í…Œì´ë¸” í†µê³„
        print("\n[1] essays í…Œì´ë¸” í†µê³„")
        print("-" * 70)

        response = await supabase.client.table("essays").select("*").execute()
        essays = response.data

        print(f"âœ“ ì´ ì—ì„¸ì´ ê°œìˆ˜: {len(essays)}")

        if len(essays) == 0:
            print("\nâš ï¸  ìƒì„±ëœ ì—ì„¸ì´ê°€ ì—†ìŠµë‹ˆë‹¤. Step 4ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return

        # 2. ìƒìœ„ 5ê°œ ì—ì„¸ì´ ìƒì„¸ ì •ë³´
        print("\n[2] ìƒìœ„ 5ê°œ ì—ì„¸ì´ (ìµœì‹ ìˆœ)")
        print("-" * 70)

        sorted_essays = sorted(essays, key=lambda x: x["generated_at"], reverse=True)

        for i, essay in enumerate(sorted_essays[:5], 1):
            print(f"\n{i}. Essay ID: {essay['id']} (Pair ID: {essay['pair_id']})")
            print(f"   ì œëª©: {essay['title']}")
            print(f"\n   [3ë‹¨ ê°œìš”]")
            for j, outline_item in enumerate(essay['outline'], 1):
                print(f"   {j}ë‹¨: {outline_item[:100]}{'...' if len(outline_item) > 100 else ''}")
            print(f"\n   [ì„ íƒ ì´ìœ ]")
            print(f"   {essay['reason'][:200]}{'...' if len(essay['reason']) > 200 else ''}")
            print(f"\n   [ì‚¬ìš©ëœ ì‚¬ê³  ë‹¨ìœ„: {len(essay['used_thoughts_json'])}ê°œ]")
            for thought in essay['used_thoughts_json']:
                print(f"   - Thought {thought['thought_id']} ({thought['source_title']})")
                print(f"     Claim: {thought['claim'][:80]}...")

        # 3. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        print("\n[3] ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦")
        print("-" * 70)

        issues = []

        for essay in essays:
            # title ê¸¸ì´ ê²€ì¦
            if len(essay["title"]) < 5 or len(essay["title"]) > 100:
                issues.append(f"Essay {essay['id']}: title length ({len(essay['title'])}) out of range [5, 100]")

            # outline ê°œìˆ˜ ê²€ì¦
            if len(essay["outline"]) != 3:
                issues.append(f"Essay {essay['id']}: outline count ({len(essay['outline'])}) != 3")

            # reason ê¸¸ì´ ê²€ì¦
            if len(essay["reason"]) > 300:
                issues.append(f"Essay {essay['id']}: reason too long (> 300 chars)")

            # used_thoughts ê²€ì¦
            if len(essay["used_thoughts_json"]) < 1:
                issues.append(f"Essay {essay['id']}: no used_thoughts")

        if issues:
            print(f"âœ— ë°œê²¬ëœ ë¬¸ì œ: {len(issues)}ê°œ")
            for issue in issues[:5]:
                print(f"  - {issue}")
        else:
            print("âœ“ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ í†µê³¼")

        # 4. thought_pairs ì‚¬ìš© ìƒíƒœ í™•ì¸
        print("\n[4] thought_pairs ì‚¬ìš© ìƒíƒœ")
        print("-" * 70)

        pairs_response = await supabase.client.table("thought_pairs").select("*").execute()
        all_pairs = pairs_response.data

        used_count = sum(1 for p in all_pairs if p["is_used_in_essay"])
        unused_count = len(all_pairs) - used_count

        print(f"âœ“ ì´ í˜ì–´: {len(all_pairs)}ê°œ")
        print(f"âœ“ ì‚¬ìš©ëœ í˜ì–´: {used_count}ê°œ")
        print(f"âœ“ ë¯¸ì‚¬ìš© í˜ì–´: {unused_count}ê°œ")

        # 5. ìš”ì•½
        print("\n" + "=" * 70)
        print("ê²€ì¦ ìš”ì•½")
        print("=" * 70)
        print(f"âœ“ ì´ ì—ì„¸ì´: {len(essays)}ê°œ")
        print(f"âœ“ ì‚¬ìš©ëœ í˜ì–´: {used_count}ê°œ")
        print(f"âœ“ ë¯¸ì‚¬ìš© í˜ì–´: {unused_count}ê°œ")
        print(f"âœ“ ë¬´ê²°ì„± ì´ìŠˆ: {len(issues)}ê°œ")

        if len(issues) == 0:
            print("\nğŸ‰ Step 4 ê²€ì¦ ì™„ë£Œ! ëª¨ë“  ì—ì„¸ì´ê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("\nâš ï¸  ì¼ë¶€ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")

    finally:
        await supabase.close()


if __name__ == "__main__":
    asyncio.run(main())
```

---

## ì˜ˆìƒ ê²°ê³¼

### Step 4 ì‹¤í–‰ ì„±ê³µ ì‹œ:
```json
{
  "success": true,
  "pairs_processed": 5,
  "essays_generated": 5,
  "essays": [
    {
      "id": 1,
      "type": "essay",
      "title": "ê²Œì„ì˜ ë‚œì´ë„ ê³¡ì„ ê³¼ êµìœ¡ì˜ ìµœì  ë„ì „: ëª°ì…ì„ ì„¤ê³„í•˜ëŠ” ë²•",
      "outline": [
        "ê²Œì„ì€ ì‰¬ìš´ ê²ƒì´ ì•„ë‹ˆë¼ ì ì ˆí•œ ë„ì „ì„ ì œê³µí•  ë•Œ ì¬ë¯¸ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ íƒêµ¬í•œë‹¤.",
        "êµìœ¡ í˜„ì¥ì—ì„œë„ í•™ìŠµìì˜ í˜„ì¬ ìˆ˜ì¤€ë³´ë‹¤ ì•½ê°„ ë†’ì€ ë‚œì´ë„ë¥¼ ì œê³µí•  ë•Œ ìµœê³ ì˜ ëª°ì…ì´ ì¼ì–´ë‚œë‹¤.",
        "ê²Œì„ ë””ìì¸ê³¼ êµìœ¡ ì„¤ê³„ì˜ ê³µí†µ ì›ë¦¬ë¥¼ í†µí•´ 'ìµœì ì˜ ë„ì „'ì´ ì°½ì˜ì„±ê³¼ ì„±ì¥ì˜ í•µì‹¬ì„ì„ ì œì‹œí•œë‹¤."
      ],
      "reason": "ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸(ê²Œì„, êµìœ¡)ì´ì§€ë§Œ 'ìµœì  ë‚œì´ë„'ë¼ëŠ” ê³µí†µ ì›ë¦¬ë¥¼ í†µí•´ ëª°ì…ê³¼ ì„±ì¥ì˜ ë³¸ì§ˆì„ íƒêµ¬í•  ìˆ˜ ìˆë‹¤. ë…ìëŠ” ê²Œì„ê³¼ í•™ìŠµì˜ ì˜ì™¸ì˜ ì—°ê²°ì ì„ ë°œê²¬í•˜ê²Œ ëœë‹¤.",
      "pair_id": 1,
      "used_thoughts": [
        {
          "thought_id": 8,
          "claim": "ê²Œì„ì„ 'ì‰¬ë©´ì„œ' í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í”Œë ˆì´ì–´ì˜ í˜„ì¬ ì‹¤ë ¥ë³´ë‹¤ ì•½ê°„ ë†’ì€ ë‚œì´ë„ë¥¼ ì œê³µí•  ë•Œ ê°€ì¥ ì¬ë¯¸ìˆë‹¤.",
          "source_title": "ê²Œì„ì€ ì‰¬ë©´ì„œ í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ëŠ” ë‚´ ìƒê°ì„ ë’·ë°›ì¹¨í•˜ëŠ” ê¸€",
          "source_url": "https://www.notion.so/..."
        },
        {
          "thought_id": 3,
          "claim": "í•™ìŠµì—ì„œ ìµœì ì˜ ë„ì „ ìˆ˜ì¤€ì€ í˜„ì¬ ëŠ¥ë ¥ë³´ë‹¤ ì•½ê°„ ë†’ì€ ì§€ì ì´ë‹¤.",
          "source_title": "êµìœ¡ì‹¬ë¦¬í•™ - ëª°ì… ì´ë¡ ",
          "source_url": "https://www.notion.so/..."
        }
      ],
      "generated_at": "2026-01-12T10:30:00Z"
    }
  ],
  "errors": []
}
```

### essays í…Œì´ë¸”:
- 5ê°œ í–‰ ìƒì„±
- title: í¥ë¯¸ë¡œìš´ ì œëª© (5-100ì)
- outline: ì •í™•íˆ 3ê°œ ë¬¸ì¥ (JSONB ë°°ì—´)
- used_thoughts_json: ì‚¬ìš©ëœ ì‚¬ê³  ë‹¨ìœ„ ì •ë³´ (JSONB ê°ì²´ ë°°ì—´)
- reason: ì„ íƒ ì´ìœ  (50-300ì)
- pair_id: ì™¸ë˜í‚¤ (thought_pairs ì°¸ì¡°)
- generated_at: ìë™ íƒ€ì„ìŠ¤íƒ¬í”„

### thought_pairs í…Œì´ë¸”:
- ì‚¬ìš©ëœ 5ê°œ í˜ì–´: is_used_in_essay = TRUE
- ë¯¸ì‚¬ìš© 5ê°œ í˜ì–´: is_used_in_essay = FALSE (ë‹¤ìŒ ì‹¤í–‰ ëŒ€ê¸°)

---

## ì£¼ì˜ì‚¬í•­ ë° íŠ¹ì´ ì¼€ì´ìŠ¤

### 1. Claude API í˜¸ì¶œ ê´€ë ¨
- **JSON íŒŒì‹± ì‹¤íŒ¨**: Step 2/3ê³¼ ë™ì¼í•œ safe_json_parse() ì‚¬ìš©
- **outlineì´ 3ê°œ ì•„ë‹˜**: Pydantic Field(..., min_length=3, max_length=3) ê²€ì¦ìœ¼ë¡œ ìë™ ì—ëŸ¬
- **title/reason ê¸¸ì´ ì´ˆê³¼**: Pydantic ê²€ì¦ìœ¼ë¡œ ìë™ ì—ëŸ¬
- **used_thoughts ëˆ„ë½**: Pydantic Field(..., min_length=1) ê²€ì¦
- **í”„ë¡¬í”„íŠ¸ì—ì„œ ëª…í™•í•œ ì§€ì‹œ**: "outlineì€ ì •í™•íˆ 3ê°œ ë¬¸ì¥", "reasonì€ í•œ ì¤„"

### 2. DB ì €ì¥ ê´€ë ¨
- **JSONB ì§ë ¬í™”**: list[str], list[dict] ìë™ ì²˜ë¦¬ë¨ (Supabase í´ë¼ì´ì–¸íŠ¸)
- **model_dump() ì‚¬ìš©**: UsedThought ê°ì²´ë¥¼ dictë¡œ ë³€í™˜
- **ì™¸ë˜í‚¤ ì œì•½**: pair_idê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì—ëŸ¬ (ì‚¬ì „ ê²€ì¦ë¨)
- **CASCADE ì‚­ì œ**: pair ì‚­ì œ ì‹œ essayë„ ìë™ ì‚­ì œ

### 3. ë¶€ë¶„ ì„±ê³µ ì²˜ë¦¬
- **ì¼ë¶€ í˜ì–´ ì‹¤íŒ¨**: try-exceptë¡œ ê°œë³„ ì²˜ë¦¬, ì„±ê³µí•œ ê²ƒë§Œ ì €ì¥
- **is_used_in_essay ì—…ë°ì´íŠ¸ ì‹¤íŒ¨**: ë¬´ì‹œ (ì—ì„¸ì´ëŠ” ì´ë¯¸ ì €ì¥ë¨)
- **ì—ëŸ¬ ë¡œê¹…**: ëª¨ë“  ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ê¸°ë¡ ë° ì‚¬ìš©ìì—ê²Œ ë³´ê³ 

### 4. í˜ì–´ ì¬ì‚¬ìš© ë°©ì§€
- **is_used_in_essay = TRUE**: ìë™ìœ¼ë¡œ ë‹¤ìŒ ì‹¤í–‰ì—ì„œ ì œì™¸ë¨
- **ìˆ˜ë™ ì¬ì‚¬ìš©**: í•„ìš” ì‹œ is_used_in_essayë¥¼ FALSEë¡œ ë³€ê²½ (SQL)
- **ì¤‘ë³µ ì—ì„¸ì´**: pair_id ì™¸ë˜í‚¤ë¡œ ì¤‘ë³µ ë°©ì§€ëŠ” ì•ˆ ë¨ (ì˜ë„ì , ì—¬ëŸ¬ ë²ˆ ìƒì„± ê°€ëŠ¥)

### 5. íƒ€ì… ì•ˆì „ì„±
- **EssayCreate ëª¨ë¸**: Pydantic ê²€ì¦ìœ¼ë¡œ íƒ€ì… ë³´ì¥
- **JSONB í•„ë“œ**: Python list/dict â†” PostgreSQL JSONB ìë™ ë³€í™˜
- **datetime ì§ë ¬í™”**: generated_atì€ ISO 8601 format

### 6. ì—ëŸ¬ ë³µêµ¬ ì „ëµ
- **Claude ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨**: raw content ë¡œê¹… + ë‹¤ìŒ í˜ì–´ ê³„ì† ì²˜ë¦¬
- **Pydantic ê²€ì¦ ì‹¤íŒ¨**: ê²€ì¦ ì—ëŸ¬ ìƒì„¸ ë¡œê¹… + ë‹¤ìŒ í˜ì–´ ê³„ì†
- **DB ì €ì¥ ì‹¤íŒ¨**: íŠ¸ëœì­ì…˜ ë¡¤ë°± + ì „ì²´ ë°°ì¹˜ ì‹¤íŒ¨ (ì¬ì‹œë„ ê°€ëŠ¥)

### 7. í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë³´ì¥
- **êµ¬ì²´ì  ì˜ˆì‹œ**: outline ê° ë‹¨ì´ ë¬´ì—‡ì„ ë‹´ì•„ì•¼ í•˜ëŠ”ì§€ ëª…ì‹œ
- **ê¸¸ì´ ì œí•œ**: ê° í•„ë“œì˜ ìµœì†Œ/ìµœëŒ€ ê¸¸ì´ ëª…ì‹œ
- **JSON í˜•ì‹**: ì •í™•í•œ JSON êµ¬ì¡° ì˜ˆì‹œ ì œê³µ
- **ì¤„ë°”ê¿ˆ ê¸ˆì§€**: reasonì€ í•œ ì¤„ë¡œ ì‘ì„± (JSONB íŒŒì‹± ì•ˆì •ì„±)

---

## ğŸ›¡ï¸ ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ (ìƒì„¸)

### ê¸°ì¡´ íŒ¨í„´ ì°¸ê³ 
Step 2/3ì˜ ê²€ì¦ëœ ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´ì„ Step 4ì—ë„ ë™ì¼í•˜ê²Œ ì ìš©í•©ë‹ˆë‹¤.

#### 1. AI Service - generate_essay() ë©”ì„œë“œ

**íŒ¨í„´ 1: Claude API í˜¸ì¶œ ì—ëŸ¬**
```python
try:
    result = await self.generate_content_with_claude(...)

    if not result["success"]:
        raise Exception(
            f"Claude API error: {result.get('error', 'Unknown error')}"
        )
except Exception as e:
    logger.error(f"Failed to generate essay: {e}")
    raise  # í˜¸ì¶œì(pipeline router)ì—ê²Œ ì „íŒŒ
```

**íŒ¨í„´ 2: JSON íŒŒì‹± ì—ëŸ¬ (safe_json_parse ì‚¬ìš©)**
```python
from services.ai_service import safe_json_parse

# Claude ì‘ë‹µ íŒŒì‹±
raw_content = result["content"]
parsed_data = safe_json_parse(raw_content)

if parsed_data is None:
    logger.error(f"JSON parse failed. Raw content: {raw_content[:500]}")
    raise ValueError(f"Invalid JSON response from Claude")
```

**íŒ¨í„´ 3: Pydantic ê²€ì¦ ì—ëŸ¬**
```python
from pydantic import ValidationError

try:
    # EssayCreate ëª¨ë¸ ê²€ì¦ (ìë™ìœ¼ë¡œ ê¸¸ì´/íƒ€ì… ì²´í¬)
    essay = EssayCreate(**parsed_data)
except ValidationError as e:
    logger.error(f"Pydantic validation failed: {e}")
    logger.error(f"Raw data: {parsed_data}")
    raise ValueError(f"Essay validation failed: {e}")
```

#### 2. Supabase Service - Essay CRUD ë©”ì„œë“œ

**íŒ¨í„´ 4: DB ì €ì¥ ì—ëŸ¬**
```python
async def insert_essay(self, essay: EssayCreate) -> dict:
    await self._ensure_initialized()

    try:
        # JSONB ì§ë ¬í™”
        essay_dict = {
            "type": essay.type,
            "title": essay.title,
            "outline": essay.outline,  # list â†’ JSONB (ìë™)
            "used_thoughts_json": [t.model_dump() for t in essay.used_thoughts],
            "reason": essay.reason,
            "pair_id": essay.pair_id
        }

        response = await self.client.table("essays")\
            .insert(essay_dict)\
            .execute()

        inserted = response.data[0]
        logger.info(f"Inserted essay ID {inserted['id']} for pair {essay.pair_id}")
        return inserted

    except Exception as e:
        logger.error(f"Failed to insert essay: {e}")
        logger.error(f"Essay data: {essay_dict}")
        raise  # í˜¸ì¶œìì—ê²Œ ì „íŒŒ
```

**íŒ¨í„´ 5: ì™¸ë˜í‚¤ ì œì•½ ìœ„ë°˜ (pair_id ì¡´ì¬ í™•ì¸)**
```python
# Routerì—ì„œ ì‚¬ì „ ê²€ì¦ (ì„ íƒ ì‚¬í•­)
try:
    pair_data = await supabase_service.get_pair_with_thoughts(pair_id)
except Exception as e:
    logger.error(f"Pair {pair_id} not found: {e}")
    raise HTTPException(
        status_code=404,
        detail=f"Pair {pair_id} does not exist"
    )
```

#### 3. Pipeline Router - generate_essays ì—”ë“œí¬ì¸íŠ¸

**íŒ¨í„´ 6: ë¶€ë¶„ ì„±ê³µ í—ˆìš© (ê°œë³„ try-except)**
```python
generated_essays: List[EssayCreate] = []
processed_pair_ids: List[int] = []

for pair in unused_pairs:
    pair_id = pair["id"]
    try:
        result["pairs_processed"] += 1

        # í˜ì–´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        pair_data = await supabase_service.get_pair_with_thoughts(pair_id)

        # Claudeë¡œ ì—ì„¸ì´ ìƒì„±
        essay_dict = await ai_service.generate_essay(pair_data)

        # Pydantic ëª¨ë¸ ìƒì„±
        essay = EssayCreate(
            title=essay_dict["title"],
            outline=essay_dict["outline"],
            used_thoughts=essay_dict["used_thoughts"],
            reason=essay_dict["reason"],
            pair_id=pair_id
        )

        generated_essays.append(essay)
        processed_pair_ids.append(pair_id)
        logger.info(f"âœ“ Essay generated for pair {pair_id}")

    except Exception as e:
        # ê°œë³„ ì‹¤íŒ¨ëŠ” ë¡œê¹…ë§Œ í•˜ê³  ê³„ì† ì§„í–‰
        error_msg = f"Failed to generate essay for pair {pair_id}: {str(e)}"
        logger.error(error_msg, exc_info=True)  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í¬í•¨
        result["errors"].append(error_msg)
        # ê³„ì† ì§„í–‰ (ë‹¤ë¥¸ í˜ì–´ëŠ” ì„±ê³µí•  ìˆ˜ ìˆìŒ)
```

**íŒ¨í„´ 7: ë¯¸ì‚¬ìš© í˜ì–´ ì—†ìŒ ì—ëŸ¬**
```python
unused_pairs = await supabase_service.get_unused_thought_pairs(limit=max_pairs)

if not unused_pairs:
    logger.warning("No unused pairs found")
    result["errors"].append("No unused pairs available. Run Step 3 first.")
    return result  # ì—ëŸ¬ ì½”ë“œ ì—†ì´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
```

**íŒ¨í„´ 8: ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨ (ì „ì²´ ë¡¤ë°±)**
```python
if generated_essays:
    try:
        logger.info(f"Saving {len(generated_essays)} essays to DB...")
        saved_essays = await supabase_service.insert_essays_batch(generated_essays)
        result["essays_generated"] = len(saved_essays)
        result["essays"] = saved_essays
        result["success"] = True

    except Exception as e:
        # ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨ ì‹œ ì „ì²´ ë¡¤ë°±
        logger.error(f"Batch insert failed: {e}", exc_info=True)
        result["errors"].append(f"Failed to save essays: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Essay batch insert failed: {str(e)}"
        )
```

**íŒ¨í„´ 9: is_used_in_essay ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ)**
```python
# ì—ì„¸ì´ëŠ” ì´ë¯¸ ì €ì¥ë¨, ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
for pair_id in processed_pair_ids:
    try:
        await supabase_service.update_pair_used_status(pair_id, is_used=True)
    except Exception as e:
        # ë¡œê¹…ë§Œ í•˜ê³  ë¬´ì‹œ (ì—ì„¸ì´ëŠ” ì´ë¯¸ ì €ì¥ë¨)
        logger.error(f"Failed to update pair {pair_id} status: {e}")
        # HTTPException ë°œìƒí•˜ì§€ ì•ŠìŒ
```

#### 4. ì—ëŸ¬ ë©”ì‹œì§€ ê°€ì´ë“œ

**ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ì‘ì„±:**

```python
# âŒ ë‚˜ìœ ì˜ˆ
raise HTTPException(status_code=500, detail="Error")

# âœ… ì¢‹ì€ ì˜ˆ
raise HTTPException(
    status_code=404,
    detail=(
        f"No unused pairs available. "
        f"Please run Step 3 first to generate thought pairs. "
        f"Current status: {len(all_pairs)} total pairs, "
        f"{used_count} already used."
    )
)
```

**ë¡œê¹… ë ˆë²¨ êµ¬ë¶„:**
- `logger.info()`: ì •ìƒ ì§„í–‰ ìƒí™© (í˜ì–´ ì¡°íšŒ ì„±ê³µ, ì—ì„¸ì´ ìƒì„± ì„±ê³µ)
- `logger.warning()`: ë¹„ì •ìƒì´ì§€ë§Œ ë³µêµ¬ ê°€ëŠ¥ (í›„ë³´ 0ê°œ â†’ fallback)
- `logger.error()`: ì—ëŸ¬ ë°œìƒ, ì¬ì‹œë„ í•„ìš” (Claude API ì‹¤íŒ¨, DB ì €ì¥ ì‹¤íŒ¨)
- `exc_info=True`: ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í¬í•¨ (ë””ë²„ê¹… í•„ìˆ˜)

#### 5. ì¬ì‹œë„ ë¡œì§ (ì„ íƒì )

**generate_essay()ì—ì„œ ì¬ì‹œë„ (safe_json_parseì™€ ìœ ì‚¬):**
```python
max_retries = 2
last_error = None

for attempt in range(max_retries + 1):
    try:
        result = await self.generate_content_with_claude(...)

        if not result["success"]:
            raise Exception(f"Claude API error: {result.get('error')}")

        raw_content = result["content"]
        parsed_data = safe_json_parse(raw_content)

        if parsed_data is None:
            raise ValueError("JSON parse failed")

        # Pydantic ê²€ì¦
        essay_data = EssayCreate.model_validate(parsed_data)

        logger.info(f"Essay generated successfully (attempt {attempt + 1})")
        return essay_data.model_dump()

    except Exception as e:
        last_error = e
        logger.warning(f"Attempt {attempt + 1}/{max_retries + 1} failed: {e}")

        if attempt < max_retries:
            logger.info("Retrying...")
            continue
        else:
            logger.error(f"All {max_retries + 1} attempts failed")
            raise last_error
```

#### 6. í…ŒìŠ¤íŠ¸ìš© ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤

êµ¬í˜„ í›„ ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸:

1. **ë¯¸ì‚¬ìš© í˜ì–´ 0ê°œ**: Step 3 ì‹¤í–‰ ì „ Step 4 í˜¸ì¶œ â†’ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€
2. **Claude API ì‹¤íŒ¨**: API í‚¤ ì˜ëª» ì…ë ¥ â†’ ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€
3. **JSON íŒŒì‹± ì‹¤íŒ¨**: safe_json_parse() ë™ì‘ í™•ì¸
4. **Pydantic ê²€ì¦ ì‹¤íŒ¨**: outline 4ê°œì¸ ì‘ë‹µ â†’ ê²€ì¦ ì—ëŸ¬
5. **DB ì €ì¥ ì‹¤íŒ¨**: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” pair_id ì‚¬ìš© â†’ ì™¸ë˜í‚¤ ì—ëŸ¬
6. **ë¶€ë¶„ ì„±ê³µ**: 5ê°œ ì¤‘ 2ê°œ ì‹¤íŒ¨ â†’ 3ê°œëŠ” ì €ì¥, 2ê°œëŠ” ì—ëŸ¬ ë¡œê¹…

---

## ğŸ”§ êµ¬í˜„ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1 ì™„ë£Œ ì¡°ê±´
- [ ] ai_service.pyì˜ generate_essay() ë©”ì„œë“œ ì¶”ê°€
- [ ] í”„ë¡¬í”„íŠ¸ ì„¤ê³„ (system_message + prompt)
- [ ] safe_json_parse() ì‚¬ìš©
- [ ] EssayCreate ëª¨ë¸ë¡œ Pydantic ê²€ì¦
- [ ] used_thoughts ë¦¬ìŠ¤íŠ¸ ìƒì„± ë¡œì§

### Phase 2 ì™„ë£Œ ì¡°ê±´
- [ ] supabase_service.pyì— 4ê°œ ë©”ì„œë“œ ì¶”ê°€
  - [ ] insert_essay()
  - [ ] insert_essays_batch()
  - [ ] get_essays()
  - [ ] get_essay_by_id()
- [ ] JSONB ì§ë ¬í™” (model_dump() ì‚¬ìš©)
- [ ] ì—ëŸ¬ ì²˜ë¦¬ (try-except + ë¡œê¹…)

### Phase 3 ì™„ë£Œ ì¡°ê±´
- [ ] /pipeline/generate-essays ì—”ë“œí¬ì¸íŠ¸
- [ ] ë¶€ë¶„ ì„±ê³µ ë¡œì§ (ì¼ë¶€ ì‹¤íŒ¨í•´ë„ ê³„ì†)
- [ ] is_used_in_essay ì—…ë°ì´íŠ¸
- [ ] /pipeline/essays ì—”ë“œí¬ì¸íŠ¸
- [ ] /pipeline/run-all í™•ì¥ (Step 4 ì¶”ê°€)

### í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì¡°ê±´
- [ ] ë¯¸ì‚¬ìš© í˜ì–´ í™•ì¸ ì¿¼ë¦¬ ì‹¤í–‰
- [ ] Step 4 ì‹¤í–‰ (curl ë˜ëŠ” Swagger UI)
- [ ] essays í…Œì´ë¸” ë°ì´í„° ê²€ì¦
- [ ] thought_pairs ì‚¬ìš© ìƒíƒœ í™•ì¸
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

### ë¬¸ì„œí™” ì™„ë£Œ ì¡°ê±´
- [ ] temp/verification/verify_step4.py ìƒì„±
- [ ] ì‹¤í–‰ ê²°ê³¼ í™•ì¸ ë° ë¬¸ì„œí™”
- [ ] README ì—…ë°ì´íŠ¸ (Step 4 ì„¹ì…˜ ì¶”ê°€)

---

## âš ï¸ ì¹˜ëª…ì  ì—ëŸ¬ ë°©ì§€ ê·œì¹™

1. **schemas/essay.py ë³€ê²½ ê¸ˆì§€**: ì´ë¯¸ ì™„ì„±ë˜ì–´ ìˆìŒ, ê·¸ëŒ€ë¡œ ì‚¬ìš©
2. **JSONB ì§ë ¬í™” í•„ìˆ˜**: list[str], list[dict] ì§ì ‘ ì €ì¥ ê°€ëŠ¥ (Supabase ìë™ ì²˜ë¦¬)
3. **model_dump() ì‚¬ìš©**: UsedThought ê°ì²´ë¥¼ dictë¡œ ë³€í™˜ í•„ìš”
4. **ë¶€ë¶„ ì„±ê³µ í—ˆìš©**: ì¼ë¶€ í˜ì–´ ì‹¤íŒ¨í•´ë„ ì„±ê³µí•œ ê²ƒì€ ì €ì¥ (try-except ê°œë³„ ì²˜ë¦¬)
5. **is_used_in_essay ì—…ë°ì´íŠ¸**: essay ì €ì¥ í›„ ë°˜ë“œì‹œ ì—…ë°ì´íŠ¸ (ì¬ì‚¬ìš© ë°©ì§€)

---

## ğŸ¯ Step 4 ì™„ë£Œ ê¸°ì¤€

ë‹¤ìŒ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ë©´ Step 4 ì™„ë£Œ:

1. âœ… ai_service.generate_essay() ë©”ì„œë“œ êµ¬í˜„ ì™„ë£Œ
2. âœ… supabase_service.pyì— 4ê°œ essay CRUD ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ
3. âœ… /pipeline/generate-essays ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ ì™„ë£Œ
4. âœ… /pipeline/essays ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ ì™„ë£Œ
5. âœ… /pipeline/run-all í™•ì¥ (Step 4 í¬í•¨) ì™„ë£Œ
6. âœ… 5ê°œ ì—ì„¸ì´ ìƒì„± ì„±ê³µ (curl í…ŒìŠ¤íŠ¸)
7. âœ… essays í…Œì´ë¸”ì— ë°ì´í„° ì •ìƒ ì €ì¥ (SQL ê²€ì¦)
8. âœ… thought_pairs.is_used_in_essay = TRUE ì—…ë°ì´íŠ¸ í™•ì¸
9. âœ… verify_step4.py ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì„±ê³µ
10. âœ… ë¬´ê²°ì„± ì´ìŠˆ 0ê°œ (title, outline, reason ê¸¸ì´ ë“±)

---

## ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„ (Step 4 ì´í›„)

### MVP ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [x] Step 1: Notion â†’ raw_notes
- [x] Step 2: raw_notes â†’ thought_units (ì„ë² ë”©)
- [x] Step 3: thought_units â†’ thought_pairs (ë‚®ì€ ìœ ì‚¬ë„ + ë™ì¼ ì¶œì²˜ ì œì™¸ + threshold)
- [ ] Step 4: thought_pairs â†’ essays (ê¸€ê° ìƒì„±)
- [ ] Frontend: Next.js ëŒ€ì‹œë³´ë“œ (ì—ì„¸ì´ ëª©ë¡ í‘œì‹œ)
- [ ] ë°°í¬: Vercel (Frontend) + Supabase (Backend)

### MVP+1 ê°œì„  (ìš°ì„ ìˆœìœ„)
1. **ë‹¤ì¤‘ Pairs ì§€ì›**: 2-5ê°œ í˜ì–´ë¥¼ ì¡°í•©í•˜ì—¬ ë” í’ë¶€í•œ ê¸€ê° ìƒì„±
2. **ìë™ ìŠ¤ì¼€ì¤„ë§**: ë§¤ì¼ ìë™ìœ¼ë¡œ ìƒˆ ê¸€ê° ìƒì„±
3. **ì‚¬ìš©ì í”¼ë“œë°±**: ì—ì„¸ì´ í‰ê°€ ë° ê°œì„  ë£¨í”„
4. **Notion ì—°ë™ ê°•í™”**: ìƒì„±ëœ ê¸€ê°ì„ Notionì— ìë™ ì €ì¥

---

**Step 4 êµ¬í˜„ í”Œëœ ì™„ë£Œ! ì´ì œ êµ¬í˜„ ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.**
