"""
Notion API integration service.
"""

import logging
from typing import List, Dict, Any
from notion_client import Client
from notion_client.errors import APIResponseError
from config import settings
from .rate_limiter import RateLimiter, ExponentialBackoff

logger = logging.getLogger(__name__)


class NotionService:
    """Service for interacting with Notion API."""

    def __init__(self):
        """Initialize Notion client with API key from settings."""
        self.client = Client(auth=settings.notion_api_key)
        self.database_id = settings.notion_database_id

        # Rate Limiter ì´ˆê¸°í™”
        self.rate_limiter = RateLimiter(rate=float(settings.rate_limit_notion))
        self.backoff = ExponentialBackoff(
            base_delay=settings.retry_base_delay,
            max_delay=settings.retry_max_delay
        )

    async def get_database_info(self) -> Dict[str, Any]:
        """
        Get database metadata.

        Returns:
            Dict containing database information
        """
        try:
            response = self.client.databases.retrieve(database_id=self.database_id)
            return {
                "success": True,
                "database_id": response["id"],
                "title": response.get("title", [{}])[0].get("plain_text", "Untitled"),
                "properties": list(response.get("properties", {}).keys()),
                "created_time": response.get("created_time"),
                "last_edited_time": response.get("last_edited_time"),
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__
            }

    async def fetch_all_database_pages(
        self,
        database_id: str | None = None,
        page_size: int = 100
    ) -> List[Dict[str, Any]]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í˜ì´ì§€ë¥¼ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°

        Args:
            database_id: íƒ€ê²Ÿ ë°ì´í„°ë² ì´ìŠ¤ ID (Noneì´ë©´ self.database_id ì‚¬ìš©)
            page_size: ë°°ì¹˜ë‹¹ í˜ì´ì§€ ìˆ˜ (ìµœëŒ€ 100)

        Returns:
            List of page objects (Notion API response format)

        Raises:
            Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        target_db_id = database_id or self.database_id
        all_pages = []
        start_cursor = None
        batch_count = 0

        logger.info(f"Starting pagination for database {target_db_id}")

        while True:
            response = None
            for retry in range(settings.max_retries):
                try:
                    # Rate limiting ì ìš©
                    await self.rate_limiter.acquire()

                    # Notion API í˜¸ì¶œ
                    response = self.client.databases.query(
                        database_id=target_db_id,
                        page_size=page_size,
                        **({"start_cursor": start_cursor} if start_cursor else {})
                    )
                    break  # ì„±ê³µ ì‹œ retry ë£¨í”„ íƒˆì¶œ

                except APIResponseError as e:
                    if e.code == 429:  # Too Many Requests
                        logger.warning(
                            f"Rate limited at batch {batch_count}, "
                            f"retrying ({retry+1}/{settings.max_retries})"
                        )
                        await self.backoff.sleep(retry)
                        continue
                    else:
                        logger.error(f"API error at batch {batch_count}: {e}")
                        raise  # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ raise

                except Exception as e:
                    logger.error(f"Unexpected error at batch {batch_count}: {e}")
                    if retry < settings.max_retries - 1:
                        await self.backoff.sleep(retry)
                        continue
                    raise

            # ì¬ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨í•œ ê²½ìš°
            if response is None:
                logger.error(f"Failed to fetch batch {batch_count} after {settings.max_retries} retries")
                raise Exception(f"Max retries exceeded for batch {batch_count}")

            # í˜„ì¬ ë°°ì¹˜ í˜ì´ì§€ ì¶”ê°€
            batch_pages = response.get("results", [])
            all_pages.extend(batch_pages)
            batch_count += 1

            logger.info(
                f"Batch {batch_count}: Fetched {len(batch_pages)} pages "
                f"(Total: {len(all_pages)})"
            )

            # ë‹¤ìŒ ë°°ì¹˜ í™•ì¸
            has_more = response.get("has_more", False)
            if not has_more:
                logger.info(f"Pagination complete: {len(all_pages)} total pages")
                break

            # ë‹¤ìŒ cursor ì„¤ì •
            start_cursor = response.get("next_cursor")
            if not start_cursor:
                logger.warning("has_more=True but no next_cursor, stopping")
                break

        return all_pages

    async def query_database(self, page_size: int = 10) -> Dict[str, Any]:
        """
        Query database and retrieve pages (wrapper for backward compatibility).

        Args:
            page_size: Number of pages to retrieve (default: 10)

        Returns:
            Dict containing query results
        """
        try:
            response = self.client.databases.query(
                database_id=self.database_id,
                page_size=page_size
            )

            pages = []
            for page in response.get("results", []):
                page_data = {
                    "id": page["id"],
                    "created_time": page.get("created_time"),
                    "last_edited_time": page.get("last_edited_time"),
                    "properties": {}
                }

                # Extract property values
                for prop_name, prop_value in page.get("properties", {}).items():
                    page_data["properties"][prop_name] = self._extract_property_value(prop_value)

                pages.append(page_data)

            return {
                "success": True,
                "total_count": len(pages),
                "has_more": response.get("has_more", False),
                "pages": pages
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__
            }

    def _extract_property_value(self, prop: Dict[str, Any]) -> Any:
        """
        Extract value from Notion property object.

        Args:
            prop: Notion property object

        Returns:
            Extracted value
        """
        prop_type = prop.get("type")

        if prop_type == "title":
            return "".join([text.get("plain_text", "") for text in prop.get("title", [])])
        elif prop_type == "rich_text":
            return "".join([text.get("plain_text", "") for text in prop.get("rich_text", [])])
        elif prop_type == "number":
            return prop.get("number")
        elif prop_type == "select":
            return prop.get("select", {}).get("name")
        elif prop_type == "multi_select":
            return [item.get("name") for item in prop.get("multi_select", [])]
        elif prop_type == "date":
            date_obj = prop.get("date", {})
            if date_obj:
                return {
                    "start": date_obj.get("start"),
                    "end": date_obj.get("end")
                }
            return None
        elif prop_type == "checkbox":
            return prop.get("checkbox")
        elif prop_type == "url":
            return prop.get("url")
        elif prop_type == "email":
            return prop.get("email")
        elif prop_type == "phone_number":
            return prop.get("phone_number")
        else:
            return f"Unsupported type: {prop_type}"

    def _extract_rich_text(self, rich_text_array: List[Dict[str, Any]]) -> str:
        """
        Notion rich_text ë°°ì—´ì—ì„œ ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            rich_text_array: Notion rich_text ê°ì²´ ë¦¬ìŠ¤íŠ¸

        Returns:
            ê²°í•©ëœ plain text ë¬¸ìì—´ (ë¹ˆ ë°°ì—´ ë˜ëŠ” Noneì´ë©´ ë¹ˆ ë¬¸ìì—´)

        Example:
            >>> service._extract_rich_text([{"plain_text": "Hello "}, {"plain_text": "World"}])
            'Hello World'

            >>> service._extract_rich_text([{"plain_text": "Hello"}, {}, {"plain_text": " World"}])
            'Hello World'

            >>> service._extract_rich_text([])
            ''

        Note:
            - missing plain_text í‚¤ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ (.get() ì‚¬ìš©)
            - ë¹ˆ ë°°ì—´ì´ë‚˜ Noneì€ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        """
        if not rich_text_array:
            return ""

        texts = [item.get("plain_text", "") for item in rich_text_array]
        return "".join(texts)

    async def fetch_page_blocks(
        self,
        page_id: str,
        max_depth: int = 2
    ) -> str:
        """
        í˜ì´ì§€ì˜ ëª¨ë“  ë¸”ë¡ì„ ê°€ì ¸ì™€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            page_id: íƒ€ê²Ÿ í˜ì´ì§€ ID
            max_depth: ì¤‘ì²© ë¸”ë¡ íƒìƒ‰ ê¹Šì´ (toggle, column ë“±)

        Returns:
            í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸ (ë§ˆí¬ë‹¤ìš´ ìŠ¤íƒ€ì¼)

        Raises:
            Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        content_parts = []
        start_cursor = None

        logger.debug(f"Fetching blocks for page {page_id}")

        while True:
            response = None
            for retry in range(settings.max_retries):
                try:
                    # Rate limiting ì ìš©
                    await self.rate_limiter.acquire()

                    # ë¸”ë¡ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§€ë„¤ì´ì…˜ ì§€ì›)
                    response = self.client.blocks.children.list(
                        block_id=page_id,
                        page_size=100,
                        **({"start_cursor": start_cursor} if start_cursor else {})
                    )
                    break  # ì„±ê³µ ì‹œ retry ë£¨í”„ íƒˆì¶œ

                except APIResponseError as e:
                    if e.code == 429:  # Too Many Requests
                        logger.warning(
                            f"Rate limited fetching blocks for page {page_id}, "
                            f"retrying ({retry+1}/{settings.max_retries})"
                        )
                        await self.backoff.sleep(retry)
                        continue
                    else:
                        logger.error(f"API error fetching blocks for page {page_id}: {e}")
                        raise  # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ raise

                except Exception as e:
                    logger.error(f"Unexpected error fetching blocks for page {page_id}: {e}")
                    if retry < settings.max_retries - 1:
                        await self.backoff.sleep(retry)
                        continue
                    # ë¸”ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨í•´ë„ ë¶€ë¶„ì ìœ¼ë¡œ ìˆ˜ì§‘ëœ ì½˜í…ì¸  ë°˜í™˜
                    logger.warning(f"Failed to fetch blocks after {settings.max_retries} retries, returning partial content")
                    break

            # ì¬ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨í•œ ê²½ìš° (ë¶€ë¶„ì ìœ¼ë¡œ ìˆ˜ì§‘ëœ ì½˜í…ì¸  ë°˜í™˜)
            if response is None:
                logger.warning(f"No response after retries for page {page_id}, returning partial content")
                break

            blocks = response.get("results", [])

            # ê° ë¸”ë¡ ì²˜ë¦¬
            for block in blocks:
                block_type = block.get("type")
                block_data = block.get(block_type, {})

                # ë¸”ë¡ íƒ€ì…ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if block_type == "paragraph":
                    text = self._extract_rich_text(block_data.get("rich_text", []))
                    if text.strip():
                        content_parts.append(text)

                elif block_type in ["heading_1", "heading_2", "heading_3"]:
                    text = self._extract_rich_text(block_data.get("rich_text", []))
                    if text.strip():
                        # ë§ˆí¬ë‹¤ìš´ ìŠ¤íƒ€ì¼ í—¤ë”
                        level = int(block_type[-1])
                        content_parts.append(f"{'#' * level} {text}")

                elif block_type in ["bulleted_list_item", "numbered_list_item"]:
                    text = self._extract_rich_text(block_data.get("rich_text", []))
                    if text.strip():
                        prefix = "-" if block_type == "bulleted_list_item" else "1."
                        content_parts.append(f"{prefix} {text}")

                elif block_type == "quote":
                    text = self._extract_rich_text(block_data.get("rich_text", []))
                    if text.strip():
                        content_parts.append(f"> {text}")

                elif block_type == "callout":
                    text = self._extract_rich_text(block_data.get("rich_text", []))
                    emoji = block_data.get("icon", {}).get("emoji", "ğŸ’¡")
                    if text.strip():
                        content_parts.append(f"{emoji} {text}")

                elif block_type == "code":
                    text = self._extract_rich_text(block_data.get("rich_text", []))
                    language = block_data.get("language", "")
                    if text.strip():
                        content_parts.append(f"```{language}\n{text}\n```")

                elif block_type == "toggle":
                    # í† ê¸€ ì œëª©ë§Œ ì¶”ì¶œ (ì¤‘ì²© ë¸”ë¡ì€ max_depth ì œì–´)
                    text = self._extract_rich_text(block_data.get("rich_text", []))
                    if text.strip():
                        content_parts.append(f"â–¶ {text}")

                # TODO: ì¶”ê°€ ë¸”ë¡ íƒ€ì… (table, image ë“±) Phase 2.5ì—ì„œ êµ¬í˜„

            # í˜ì´ì§€ë„¤ì´ì…˜ ì²´í¬
            has_more = response.get("has_more", False)
            if not has_more:
                break

            start_cursor = response.get("next_cursor")

        # í…ìŠ¤íŠ¸ ê²°í•© (ê° ë¸”ë¡ ì‚¬ì´ ë¹ˆ ì¤„)
        full_content = "\n\n".join(content_parts)
        logger.debug(f"Extracted {len(full_content)} characters from page {page_id}")

        return full_content

    async def fetch_child_pages_from_parent(
        self,
        parent_page_id: str,
        page_size: int = 100
    ) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • í˜ì´ì§€ì˜ í•˜ìœ„ í˜ì´ì§€ë“¤ì„ ê°€ì ¸ì˜¤ê¸°

        Args:
            parent_page_id: ë¶€ëª¨ í˜ì´ì§€ ID (URLì—ì„œ ì¶”ì¶œí•œ 32ì ID)
            page_size: ë°°ì¹˜ë‹¹ í˜ì´ì§€ ìˆ˜ (ìµœëŒ€ 100)

        Returns:
            List of child page objects (Notion API format)

        Raises:
            Exception: Notion API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        all_child_pages = []
        start_cursor = None
        batch_count = 0

        logger.info(f"Fetching child pages from parent: {parent_page_id}")

        while True:
            response = None
            for retry in range(settings.max_retries):
                try:
                    # Rate limiting ì ìš©
                    await self.rate_limiter.acquire()

                    # blocks.children.list() API í˜¸ì¶œ
                    response = self.client.blocks.children.list(
                        block_id=parent_page_id,
                        page_size=page_size,
                        **({"start_cursor": start_cursor} if start_cursor else {})
                    )
                    break  # ì„±ê³µ ì‹œ retry ë£¨í”„ íƒˆì¶œ

                except APIResponseError as e:
                    if e.code == 429:  # Too Many Requests
                        logger.warning(
                            f"Rate limited at batch {batch_count}, "
                            f"retrying ({retry+1}/{settings.max_retries})"
                        )
                        await self.backoff.sleep(retry)
                        continue
                    else:
                        logger.error(f"API error fetching child pages: {e}")
                        raise  # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ raise

                except Exception as e:
                    logger.error(f"Unexpected error fetching child pages: {e}")
                    if retry < settings.max_retries - 1:
                        await self.backoff.sleep(retry)
                        continue
                    raise

            # ì¬ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨í•œ ê²½ìš°
            if response is None:
                logger.error(f"Failed to fetch batch {batch_count} after {settings.max_retries} retries")
                raise Exception(f"Max retries exceeded for batch {batch_count}")

            blocks = response.get("results", [])

            # child_page íƒ€ì…ì˜ ë¸”ë¡ë§Œ í•„í„°ë§
            child_pages = []
            for block in blocks:
                if block.get("type") == "child_page":
                    # Child pageëŠ” ìƒì„¸ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ pages.retrieve() í˜¸ì¶œ í•„ìš”
                    child_page_id = block.get("id")

                    try:
                        await self.rate_limiter.acquire()
                        page_data = self.client.pages.retrieve(page_id=child_page_id)
                        child_pages.append(page_data)
                    except Exception as e:
                        logger.warning(f"Failed to retrieve child page {child_page_id}: {e}")
                        continue

            all_child_pages.extend(child_pages)
            batch_count += 1

            logger.info(
                f"Batch {batch_count}: Fetched {len(child_pages)} child pages "
                f"(Total: {len(all_child_pages)})"
            )

            # í˜ì´ì§€ë„¤ì´ì…˜ ì²´í¬
            has_more = response.get("has_more", False)
            if not has_more:
                logger.info(f"Pagination complete: {len(all_child_pages)} total child pages")
                break

            start_cursor = response.get("next_cursor")
            if not start_cursor:
                logger.warning("has_more=True but no next_cursor, stopping")
                break

        return all_child_pages


def get_notion_service() -> NotionService:
    """
    Get NotionService instance.

    Returns:
        NotionService instance
    """
    return NotionService()
