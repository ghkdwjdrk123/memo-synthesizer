# Embedding 유사도 분포 문제 분석

## 📋 문제 요약

노션 메모에서 추출한 1,909개 thought_units의 임베딩 벡터 간 코사인 유사도가 예상보다 매우 높게 나타남.
"약한 연결"을 찾기 위해 0.05~0.35 범위를 설정했으나, 실제 데이터는 0.26 이상에만 집중되어 있음.

---

## 📊 현재 상황

### 데이터 구성
- **thought_units**: 1,909개
- **raw_notes**: 734개 (평균 2.6개 thought per note)
- **임베딩 모델**: OpenAI `text-embedding-3-small` (1536차원)

### 유사도 분포 (Top-K=20 기준)

| 유사도 범위 | 목표 개수 | 실제 개수 | 설명 |
|------------|----------|----------|------|
| Low (0.05-0.15) | 40개 | **0개** | 창의적 조합 (약한 연결) |
| Mid (0.15-0.25) | 35개 | **0개** | 보통 연결 |
| High (0.25-0.35) | 25개 | **776개** | 강한 연결 |
| Very High (0.35-0.45) | - | **1000+개** | 매우 강한 연결 |

**실제 수집된 유사도:**
- 최소: 0.2637
- 최대: 0.5000 (매우 높음)
- 평균: 0.35 이상

---

## 🎯 원래 의도 (하이브리드 C 전략)

### 샘플링 전략 목표
"약한 연결"을 찾아 창의적인 아이디어 조합 생성:
- **Low (0.05-0.15)**: 40개 - 서로 다른 주제의 창의적 연결
- **Mid (0.15-0.25)**: 35개 - 중간 수준의 연결
- **High (0.25-0.35)**: 25개 - 어느 정도 유사한 연결

### 현재 결과
- 샘플링 목표: 100개
- 실제 샘플: 25개 (High 구간만)
- **Low/Mid 구간 후보가 전혀 없어서 다양성 샘플링 실패**

---

## 🔍 원인 분석

### 가설 1: 도메인 특성
- 734개 노션 메모가 모두 **비슷한 주제/도메인**에 관한 것
- 개인의 관심사가 일관적이라 사고 패턴이 유사
- 예: 모두 기술 블로그, 개발 노트, 특정 분야 학습 자료 등

### 가설 2: 임베딩 모델 특성
- `text-embedding-3-small`이 한국어 텍스트에서 높은 유사도를 생성
- 짧은 텍스트(claim: 10-500자)에서 유사도가 높게 나타나는 경향
- 모델이 의미적 차이를 충분히 구분하지 못함

### 가설 3: Thought 추출 방식
- Claude가 한 노트에서 추출한 thought들이 이미 유사성이 높음
- Context가 제한적이라 추상화 수준이 높아짐
- 예: "게임은 명확한 목표를 제공한다" vs "높은 레벨은 노력을 나타낸다"
  → 둘 다 "게임" 도메인이라 유사도 높음

---

## 🧪 실험 데이터

### Top-K=20, min_sim=0.05, max_sim=0.35
```
수집된 후보: 776개
유사도 범위: 0.2637 ~ 0.3500
```

### Top-K=20, min_sim=0.05, max_sim=0.50
```
수집된 후보: 1000+개
유사도 범위: 0.2637 ~ 0.5000
Low/Mid 구간: 여전히 0개
```

### Top-K=100 시도
```
결과: Statement timeout (쿼리 시간 초과)
이유: 1909 × 100 = 190,900번의 벡터 유사도 계산
```

---

## 📐 기술적 배경

### 코사인 유사도 계산
```python
similarity = 1 - cosine_distance(embedding_a, embedding_b)
```

- **1.0**: 완전히 동일한 방향 (매우 유사)
- **0.5**: 중간 각도 (어느 정도 유사)
- **0.0**: 직교 (완전히 다름)

### pgvector 연산
```sql
similarity = 1 - (embedding_a <=> embedding_b)
-- <=> 연산자: 코사인 거리 (0~2 범위)
```

### HNSW 인덱스 활용
```sql
ORDER BY embedding <=> query_embedding
LIMIT top_k
```
- 가장 가까운(유사한) 벡터 K개 반환
- 먼 벡터(낮은 유사도)는 검색 안 됨

---

## 🤔 질문 사항

### 1. 임베딩 모델 특성
- `text-embedding-3-small`이 한국어에서 유사도를 높게 측정하는 경향이 있는가?
- 짧은 텍스트(10-500자)에서 임베딩 품질이 떨어지는가?
- 더 나은 대안 모델이 있는가? (예: multilingual-e5-large, BGE 등)

### 2. 유사도 범위 설정
- 0.26 이상의 유사도도 "약한 연결"로 볼 수 있는가?
- 창의적인 아이디어 조합을 위한 적절한 유사도 범위는?
- 도메인 특성에 따라 범위를 동적으로 조정해야 하는가?

### 3. Top-K 알고리즘 한계
- HNSW는 가장 가까운 K개만 찾음 → 먼 벡터(낮은 유사도)를 찾는 방법은?
- 전체 O(n²) 계산 없이 낮은 유사도 페어를 찾는 효율적인 방법은?

### 4. 데이터 특성
- 734개 노트가 모두 유사한 주제일 가능성이 높은가?
- 더 다양한 주제의 메모를 수집해야 하는가?
- Thought 추출 프롬프트를 개선하여 더 다양한 관점을 추출할 수 있는가?

---

## 💡 고려 중인 해결책

### Option A: 유사도 범위 조정
```
기존: 0.05 ~ 0.35
조정: 0.20 ~ 0.45
```
- 장점: 현재 데이터로 즉시 진행 가능
- 단점: 원래 의도("약한 연결")에서 벗어남

### Option B: 임베딩 모델 변경
```
현재: text-embedding-3-small
대안: multilingual-e5-large, BGE-M3
```
- 장점: 더 나은 의미 구분 가능성
- 단점: 1909개 재임베딩 필요 (비용/시간)

### Option C: Negative Sampling
```sql
-- 가장 먼 벡터도 샘플링
ORDER BY embedding <=> query_embedding DESC
LIMIT K
```
- 장점: 낮은 유사도 페어 강제 생성
- 단점: 의미적으로 너무 다를 수 있음 (품질 문제)

### Option D: 데이터 다양화
- 더 다양한 주제의 노션 메모 수집
- Thought 추출 프롬프트 개선

---

## 📝 참고 정보

### 프로젝트 목표
"노션 메모에서 **약한 연결**을 찾아 창의적인 Essay 주제 생성"

### 하이브리드 C 전략
```
pair_candidates (전체 후보 보관)
  ↓
초기 샘플링 (유사도 구간별 100개)
  ↓
LLM 평가 (Claude로 논리적 확장 가능성 평가)
  ↓
thought_pairs (고품질만 저장)
```

### 기술 스택
- PostgreSQL + pgvector (HNSW 인덱스)
- OpenAI text-embedding-3-small (1536차원)
- Supabase (호스팅)

---

## 🎯 원하는 결과

1. **유사도 분포 분석**: 왜 Low/Mid 구간이 없는지 원인 파악
2. **해결 방안 제시**: 현실적이고 효율적인 해결책
3. **모범 사례**: 유사한 프로젝트에서의 접근법

---

**생성일**: 2026-01-26
**버전**: 1.0.0
**상태**: 분석 진행 중
